---
title: "Study 1 Analysis"
author:
- name: Thomas E. Gorman
  url: https://tegorman13.github.io/
  affiliations: 
  - name:  Communication and Cognition Lab, Purdue University, USA
    affiliation-url: https://web.ics.purdue.edu/~treimer/
lightbox: true
toc: false
code-fold: true
code-tools: true
execute:
  #echo: false
  warning: false
format:
  html: 
    grid:
      sidebar-width: 220px
      body-width: 1200px
      margin-width: 170px
      gutter-width: 1.0rem
  hugo-md:
    include: true
    html-math-method: mathjax
    output-file: s1_hugo.md
  gfm:
    echo: true
    output-file: s1_gfm.md
---


```{r}
library(pacman)
pacman::p_load(dplyr,purrr,tidyr,here,haven,tibble,brms,bayestestR,emmeans,tidybayes,modelsummary,
               ggplot2,gt,ggh4x,lme4,flextable,kableExtra)

options(digits=2, scipen=999, dplyr.summarise.inform=FALSE)
walk(c("fun_plot"), ~ source(here::here(paste0("Scripts/", .x, ".R"))))
theme_set(theme_nice())
```



```{r}
#| eval: FALSE

# s1 <- haven::read_sav(here::here("data/data_qualtrics/Frequency & Probability - 9-23-18_October 6, 2024_20.39.sav")) # length(unique(s1$ResponseId)) = 588
# qd <- unique(s1$ResponseId)

s1 <- haven::read_sav(here::here("data/Frequency & Probability Study 1 - 3-24-19.sav"))

#gd <- unique(s1$ResponseId)
# gd %in% qd
# qd %in% gd

s1 <- s1 |> 
  mutate(
    state1 = case_when(
      Colorado == 1 ~ "Colorado",
      Massachusetts == 1 ~ "Massachusetts",
      California == 1 ~ "California",
      Texas == 1 ~ "Texas",
      TRUE ~ NA_character_
    ),
    state2 = case_when(
      Colorado == 2 ~ "Colorado",
      Massachusetts == 2 ~ "Massachusetts",
      California == 2 ~ "California",
      Texas == 2 ~ "Texas",
      TRUE ~ NA_character_
    )) |> 
  mutate(refClass = case_when(
  ReferenceClass == 1 ~ "USD",
  ReferenceClass == 2 ~ "kWh",
  ReferenceClass == 3 ~ "Percentage"
)) |> 
  rename(calc=MATH01) |>  # replace NA's in calc with 0's
  rename(id2=ResponseId) |>
  mutate(id=row_number()) |> relocate(id) |> 
  mutate(calc=factor(ifelse(is.na(calc),0,calc))) |> 
  relocate(refClass,state1,state2,calc, .after = id) 


s1 <- s1 |> rename(edu=DEM04) |>
  mutate(edu = factor(case_when(
    edu == 1 ~ "Some schooling, but no diploma or degree",
    edu == 2 ~ "Highschool diploma or GED",
    edu == 3 ~ "Some college",
    edu == 4 ~ "College degree",
    edu == 5 ~ "Some graduate school",
    edu == 6 ~ "Graduate degree",
    edu == 7 ~ "Choose not to answer",
    TRUE ~ NA_character_
  ))) |> relocate(edu, .after = id) 

# colnames(s1)
# colnames(s1)[1000:1500]
# colnames(s1)[1500:1843]

# select all columns that start with "A"
# s12 <- s1 |> select(id,state1,state2,refClass,calc,edu,starts_with("A")) |> 
#   select(-starts_with("AIND"))




 
 
# 
# t <- s12 |> filter(state1=="Texas") |> 
#   # select only columns that contain "TEX" in the name
#   select(id,state1,state2,refClass,calc,edu,contains("TEX")) 
# 
# t2 <- s12 |> filter(state2=="Texas") |> 
#   select(id,state1,state2,refClass,calc,edu,contains("TEX"))
# 

trim_na_and_empty_columns <- function(df) {
  df %>%
    select(where(~!(all(is.na(.)) | (is.character(.) && all(trimws(.) == ""))))) |> 
    select(-starts_with("AIND"))
}


# Create a list of trimmed datasets for each unique ID
dAll <- s1 %>%
  group_by(id) %>%
  group_split() %>%
  map(trim_na_and_empty_columns) %>%
  set_names(unique(s1$id))

# modalities <- c(A = "kWh", D = "USD", P = "Percentage")
# states <- c(CAL = "California", MASS = "Massachusetts", COL = "Colorado", TEX = "Texas")


parse_action_plan <- function(df) {
  
  action_plan_cols <- df %>% 
  select(-matches("01$|02$|03$|04$|05$|06$|33$|34$|35$|36$|37$")) %>%
    select(
      matches("^[ADP]\\d+(CAL|MASS|COL|TEX)\\d{2,3}$"), #,  # Select action plan columns
      -matches("32$")                                     # Exclude columns ending with '32'
    ) %>%
    names()

  df_long <- df %>%
  select(-matches("01$|02$|03$|04$|05$|06$")) %>%
    pivot_longer(
      cols = all_of(action_plan_cols),
      names_to = c("modality", "state", "item_num"),
      names_pattern = "^([ADP])\\d+(CAL|MASS|COL|TEX)(\\d+)$",
      values_to = "value"
    ) |> select(id,state1,state2,refClass,calc,edu,modality,state,item_num,value,id2,Duration__in_seconds_) 
  
  df_long <- df_long |> 
  mutate(
    appliance = case_when(
      item_num %in% c("07","08","09",7:10) ~ "Cooling",
      item_num %in% 11:14 ~ "Heating",
      item_num %in% 15:18 ~ "Water Heating",
      item_num %in% 19:22 ~ "Refrigerator",
      item_num %in% 23:26 ~ "Other Appliance",
      item_num %in% 27:30 ~ "Total kWh",
      item_num == 31 ~ "Preferred Plan",
      item_num %in% 33:37 ~ "Reduction Choices",
      TRUE ~ NA_character_
    )
  ) |> 
  # item_type - family, state, plan1 or plan2
  mutate(item_type=case_when(
    item_num %in% c("07","11","15","19","23","27") ~ "family",
    item_num %in% c("08","12","16","20","24","28") ~ "state_avg",
    item_num %in% c("09","13","17","21","25","29") ~ "plan1",
    item_num %in% c("10","14","18","22","26","30") ~ "plan2",
    TRUE ~ "other"
  )) 

# pivot family and state_avg into their own separate columns, plan1 and plan2 into a combined column called plan
df_long <- df_long |> 
  filter(item_type !="other") |> 
  select(-item_num) |> 
  pivot_wider(names_from = c("item_type"), values_from = value) |> 
  pivot_longer(cols = c("plan1","plan2"), names_to = "plan", values_to = "value") 
  
}

test <- dAll |> # map each item in dAll into parse function
  map(parse_action_plan) 
  
s1 <- bind_rows(test)

s1 <- s1 |> group_by(id) |> 
  mutate(trial=row_number(), block=ifelse(trial>=12,2,1), plan=as_factor(plan),pct_goal=.15) |> 
  select(-trial)

# for id R_1kFwgoKAmNTwCs3 - when state== TEX, appliance == Heating, check values of family column
s1 |> filter(id2=="R_1kFwgoKAmNTwCs3" & state=="TEX" & appliance=="Heating") |> select(family) 
# for id R_1kFwgoKAmNTwCs3 - when state== TEX, appliance == Heating, set values of family column to 6118
s1 <- s1 |> mutate(family=ifelse(id2=="R_1kFwgoKAmNTwCs3" & state=="TEX" & appliance=="Heating",6118,family))

s1 <- s1 |> 
  mutate(change = value-family, 
         state_p_dif = value-state_avg,
         state_f_dif= family-state_avg,
         less_avg = value<state_avg,
         calc = if_else(calc == 0, "No Calculator", "Used Calculator")) |> 
  mutate(value=as.numeric(value))


saveRDS(s1, here::here("data/s1_processed.rds"))

```



```{r}
s1 <- readRDS(here::here("data/s1_processed.rds"))



s1_agg <- s1 |> 
  filter(appliance !="Total kWh") |> 
  group_by(id,refClass,state,block,plan,calc,edu,pct_goal) |> 
  summarise(total_kWh = sum(value),orig_kWh=sum(family), 
            pct_change = round((orig_kWh-total_kWh)/orig_kWh,3), 
            n_change = sum(value!=family),
            state_p_dif=mean(state_p_dif),
            state_f_dif=mean(state_f_dif),
            n_less_avg = sum(less_avg),
            duration=first(Duration__in_seconds_)) |> 
  mutate(matched_goal = (pct_change == pct_goal), 
             error = pct_change - pct_goal,
            abs_error = abs(error),
            close_match = abs_error <= 0.02)

# s1_agg |> filter(matched_goal==FALSE, abs_error<.02) |> pull(abs_error)


s1_agg4 <- s1_agg |> group_by(id,refClass) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) 

s1_agg2 <- s1_agg |> group_by(id,refClass,state) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) 

outliers <- s1_agg |>  ungroup() |> group_by(state) |> mutate(change_mean=mean(pct_change,na.rm=TRUE),change_sd=sd(pct_change,na.rm=TRUE),
                                     z_score=(pct_change-change_mean)/change_sd,
                                     is_outlier=abs(z_score)>3.0)
outlier_id <- outliers |> filter(is_outlier) |> pull(id) |> unique()





# plot frequency dist of values of n_change
s1_agg |> ggplot(aes(x=n_change)) +
  geom_bar(fill = 'dodgerblue4',width=1) +
  theme_minimal() 

# examine relationship between n_change and whether goal was matched
s1_agg |> ggplot(aes(x=n_change,fill=matched_goal)) +
  geom_bar(position="dodge") +
  theme_minimal() +
  labs(title="Relationship between # of changes and whether goal was matched",
       x="# of changes",
       y="Count") +
  scale_fill_brewer(palette="Set2")

# alternative way to examine the relationship, not a plot
s1_agg |> group_by(n_change,matched_goal) |> summarise(n=n()) |> 
  gt() |> tab_header(title="Relationship between # of changes and whether goal was matched")



s1 |> 
  filter(appliance !="Total kWh") |> 
  group_by(state, appliance) |> 
  summarise(family=mean(family),state_avg=mean(state_avg),dif=family-state_avg)


s1 |> ungroup() |> mutate(diff=family-state_avg) |> group_by(state,appliance) |>  summarize(min(diff))

s1 |> ungroup() |> mutate(diff=family-state_avg) |> group_by(state) |> filter(diff<0) |> select(id,state1,state2,state,appliance,family,state_avg,plan,value,diff)


# examine the relationship between n_less_avg (a value btw 0 and 5) and whether goal was matched
s1_agg |> ggplot(aes(x=n_less_avg,fill=matched_goal)) +
  geom_bar(position="dodge") +
  facet_wrap(~state) +
  theme_minimal() +
  labs(title="Relationship between # of appliances changed to below state average and whether goal was matched",
       x="# of appliances changed to below state average",
       y="Count") +
  scale_x_continuous(breaks=seq(1,5,1)) 




```



```{r}
#| panel: tabset
#| output: asis

t1 <- datasummary_crosstab(data=s1_agg |> group_by(id) |> slice(1),
                           calc~refClass,
                           statistic = 1 ~ N + Percent("row"),
                           output='markdown')
t2 <- datasummary(data=s1_agg4 ,(` `= pct)*refClass ~ Mean+Median+Mode+sd+Histogram,output='markdown',title="% of trials where goal was matched")
t3 <- datasummary(data=s1_agg, pct_change*refClass~Mean+Median+Mode, output='markdown')
list_of_tables <- list(t1,t2,t3)
names(list_of_tables) <- c("Calculator by Ref Class tallies","% of trials with matched goal","% change in plan")

for (itable in names(list_of_tables)) {
  cat(sprintf("\n## %s\n\n", itable))
  print(list_of_tables[[itable]])
}

```


```{r}





plot_hist_condit <- function(fcondit,dat,pvar) {
  full_range <- dat |> pull({{pvar}}) |> range(na.rm=TRUE)
  dat |>
    filter(refClass == fcondit) |> 
    ggplot(aes(.data[[pvar]])) +
    geom_bar(fill = 'dodgerblue4',width=1) +
    theme_minimal() #+ coord_cartesian(xlim = full_range)
}


s1_agg4 |> group_by(refClass) |> 
  summarise(Mean=mean(pct), Median=median(pct),Mode=modeest::mlv(pct,method='mfv'), sd=sd(pct), n=n()) |> 
  mutate(Distribution=refClass) |> rename("Reference Class"=refClass) |>  
  gt() |> 
  tab_header(title="Descriptive Statistics of % of trials with matched goal") |> 
  text_transform(
    locations=cells_body(columns='Distribution'),
    fn=function(column) {
      map(column,plot_hist_condit,dat=s1_agg4,pvar='mg') |> 
        ggplot_image(height=px(50),aspect_ratio=2)
    }
  )

ggplot(s1_agg |> filter(abs_error<1), aes(x = refClass, y = abs_error, fill = refClass)) +
    geom_boxplot() +
    labs(
        title = "Absolute Error by Reference Class",
        x = "Reference Class",
        y = "Absolute Error"
    ) +
    theme_minimal()

ggplot(s1_agg |> filter(abs_error<1), aes(x = abs_error, fill = refClass)) +
    geom_histogram(binwidth = 0.05, alpha = 0.6, position = "identity") +
    labs(
        title = "Distribution of Absolute Error by Reference Class",
        x = "Absolute Error",
        y = "Frequency"
    ) +
    theme_minimal() + facet_wrap(~refClass)
```


```{r}
#| eval: FALSE


m_zib <- brm(
  bf(pct ~ refClass + (1|id),
     zi ~ refClass + (1|id)),
  family = zero_inflated_beta(),
  data = s1_agg4
)

m_bb <- brm(
  pct ~ refClass + (1|id),
  family = beta_binomial(),
  data = s1_agg4
)


m_bb <- brm(
    successes | trials(4) ~ refClass,
    family = beta_binomial(),
    data = s1_agg4 |> 
        mutate(successes = pct * 4)  # convert proportion back to count
)
# Regression Coefficients:
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept             -0.52      0.01    -0.55    -0.49 1.00     4003     3155
# refClassPercentage    -0.73      0.02    -0.77    -0.69 1.00     3603     2648
# refClassUSD           -1.74      0.02    -1.79    -1.69 1.00     3478     3007
# 
# Further Distributional Parameters:
#     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# phi     0.33      0.00     0.33     0.34 1.00     3255     2429

# > m_bb |> emmeans(~refClass, type="response")
#  refClass   prob lower.HPD
#  upper.HPD
#  kWh        0.37      0.37      0.38
#  Percentage 0.22      0.22      0.23
#  USD        0.09      0.09      0.10


m_bb |> emmeans(~refClass)
m_bb |> emmeans(~refClass, type="response")


m_bb_re <- brm(
    successes | trials(4) ~ refClass + (1|id),
    family = beta_binomial(),
    cores=4,
    data = s1_agg4 |> 
        mutate(successes = pct * 4)
)







m_bb2 <- brm(
    mg | trials(4) ~ 0+refClass,
    family = beta_binomial(link = "identity", link_phi = "identity"),
    chains=2,
    cores=2,
    data = s1_agg4
)

m_bb3 <- brm(
    mg | trials(2) ~ 0+refClass,
    family = beta_binomial(link = "identity", link_phi = "identity"),
    chains=2,
    cores=2,
    data = s1_agg2
)
# Regression Coefficients:
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# refClasskWh            0.38      0.00     0.38     0.38 1.00     1900     1385
# refClassPercentage     0.22      0.00     0.22     0.22 1.00     1868     1549
# refClassUSD            0.09      0.00     0.09     0.10 1.00     2608     1328
# 
# Further Distributional Parameters:
#     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# phi     0.17      0.00     0.17     0.18 1.00      813      940


m_bb4 <- brm(
    mg | trials(2) ~ refClass + (1|id),
    family = beta_binomial(),
    chains=2,
    cores=2,
    data = s1_agg2
)


m_t1 <- brm(matched_goal ~ refClass + (1|id), family = bernoulli(), data = s1_agg)
 m_t1 |> emmeans(~refClass, type="response")


# 
# m_zib <- brm(
#   bf(pct ~ refClass + (1|id),
#      zi ~ refClass + (1|id)),
#   family = zero_inflated_beta(),
#   iter=2000,
#   cores=4,
#   data = s1_agg4 |> mutate( pct = ifelse(pct == 1, 0.999, ifelse(pct == 0, 0.001, pct)))
# )
# Multilevel Hyperparameters:
# ~id (Number of levels: 242) 
#                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# sd(Intercept)        0.09      0.07     0.00     0.26 1.00     2164     1682
# sd(zi_Intercept)     0.77      0.63     0.03     2.32 1.00     2846     1826
# 
# Regression Coefficients:
#                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept                -0.37      0.16    -0.67    -0.06 1.00     5376     2635
# zi_Intercept             -8.17      3.46   -17.15    -3.80 1.00     2673     1375
# refClassPercentage       -0.43      0.22    -0.87     0.00 1.00     5054     2984
# refClassUSD              -0.69      0.21    -1.10    -0.28 1.00     4759     2772
# zi_refClassPercentage    -0.04      4.78   -10.32    10.04 1.00     2037     1627
# zi_refClassUSD            0.47      4.50    -8.53    10.19 1.00     2181     1665
 
 
 
 s1_agg |> group_by(id,refClass) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) |> 
   group_by(refClass) |> 
  summarise(mean_pct=mean(pct), sd_pct=sd(pct), n=n()) 
 
 
 
 post <- posterior_samples(m_t1)
nsims <- 1000
re_sims <- rnorm(nsims, 0, mean(post$sd_id__Intercept))
```


```{r}
#| eval: false
s1_agg |> ggplot(aes(x=pct_change)) +
  geom_density(aes(fill=state), alpha=0.5) +
  ggdist::stat_halfeye() +
  geom_rug(alpha=0.1) +
  stat_boxplot(width=0.5, alpha=0.6) +
  #facet_wrap(~refClass) +
  labs(title="Distribution of Percent Change by State and Reference Class - Before outlier exclusion",
       x="Percent Change",
       y="Density") +
  scale_fill_brewer(palette="Set2")

# descriptive table to do with plot
s1_agg |> 
  group_by(refClass,state) |> 
  summarise(mean_pct_change=median(pct_change), sd_pct_change=sd(pct_change), n=n()) |> 
  gt() |> 
  tab_header(title="Descriptive Statistics of Percent Change by State and Reference Class")


s1_agg <- s1_agg |> filter(!id %in% outlier_id)

```




```{r}
#| fig.width: 10
#| fig.height: 9

  # add geom_vline with x intercept based on pct_goal of the data (which is currently a string of form 10%)
s1_agg |> 
  filter(block==1) |>
  ungroup() |> 
  mutate(id=reorder(id,pct_change)) |> 
  ggplot(aes(y=id,x=pct_change)) + 
  geom_point(size=1,alpha=0.6,position = position_jitter(w=0, h=0.17)) +
  geom_vline(aes(xintercept=.15),linetype="dashed",alpha=.5) +
  ggh4x::facet_nested_wrap(~refClass,axes="all",scales="free",ncol=2)  + 
  labs(y="Participant Id", x="Percent Change", title="Individual Performance") +
  theme(axis.text.y = element_text(family = "Manrope Light", face = "plain", size = rel(0.7)))
```





## Looking at % of subjects who hit the target reduction

```{r}


# Step 2: Summarize the percentage of participants meeting the goal for each condition
summary_pct <- s1_agg |>
  group_by(refClass) |>
  summarise(
    matched_count = sum(matched_goal),
    matched_count2 = sum(close_match),
    total_count = n(),
    pct_matched = matched_count / total_count * 100,
    .groups = "drop"
  )

# Step 3: Create plots for the percentage of subjects in each condition who matched the target pct
ggplot(summary_pct, aes(x = refClass, y = pct_matched, fill = refClass)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Percentage of Participants Matching Target Pct by Condition",
    x = "Reference Class",
    y = "Percentage Matched (%)",
    fill = "Rounding"
  ) +
  theme_minimal()

ggplot(summary_pct, aes(x = refClass, y = matched_count2, fill = refClass)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Percentage of Participants Matching Target Pct by Condition - 2% leeway",
    x = "Reference Class",
    y = "Percentage Matched (%)",
    fill = "Rounding"
  ) +
  theme_minimal()





s1_agg |> group_by(id,refClass) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) |> 
  ggplot(aes(x=pct)) +
  geom_density(aes(fill=refClass), alpha=0.5) 

# histogram
s1_agg |> group_by(id,refClass) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) |> 
  ggplot(aes(x=pct)) +
  geom_bar(aes(fill=refClass)) +
  ggdist::stat_halfeye() +
  geom_rug(alpha=0.1) +
  stat_boxplot(width=0.5, alpha=0.6) +
  facet_wrap(~refClass) +
  labs(title="Distributions of % of trials that matched goal",
       x="% of trials (out of 4) that matched goal",
       y="Number of Participants",
       fill="Reference Class") +
  scale_fill_brewer(palette="Set2") + 
  scale_y_continuous(breaks=seq(0,80,5)) + scale_x_continuous(breaks=seq(0,1,.25),labels=scales::percent_format(accuracy=1)) 
  

# s1_agg |> group_by(id,refClass) |> 
#   summarise(mg=sum(matched_goal),n=n(), pct=mg/n) |> 
#   group_by(refClass) |>
#   summarise(mean_pct=mean(pct), sd_pct=sd(pct), n=n()) 

s1_agg |> group_by(id,refClass) |> 
  summarise(mg=sum(matched_goal), n=n(), pct=mg/n) |> 
  group_by(refClass,mg) |>
  summarise(n=n()) |>  rename("# matched goal"=mg,"# participants"=n) |> gt() |>  tab_header(
    title = md("**Number of Trials participants match goal by Reference class**"),
    subtitle = "Each participant had 4 trials where they attempt to create a plan to match goal"
  ) 
  
  # setNames(c("refClass", "# of trials with matched goal", "n")) |>
  # knitr::kable(booktabs=T,col.names = c("Reference Class", 
  #                           "# of correct trials ",
  #                           "n"),
  #              format = "html") |> 
  # kableExtra::kable_styling(full_width = F) |> column_spec(1:3, width = "2cm")
  






summary_pct |>
  gt() |>
  tab_header(
    title = md("**Percentage of Trials Matching Target Pct by Condition**"),
    subtitle = "Grouped by Reference Class, Rounding, and Pct Goal"
  ) |>
  fmt_number(
    columns = c(pct_matched),
    decimals = 2
  ) |>
  cols_label(
    refClass = "Reference Class",
    matched_count = "Matched Count",
    total_count = "Total Count",
    pct_matched = "Percentage Matched (%)"
  ) |>
  cols_align(
    align = "center",
    columns = everything()
  ) |>
  tab_spanner(
    label = "Participants",
    columns = c(matched_count, total_count, pct_matched)
  )

```



```{r}
#| eval: FALSE


contingency_table <- s1_agg %>%
    group_by(refClass) %>%
    summarise(
      matched = sum(matched_goal),
      unmatched = n() - sum(matched_goal)
    ) %>%
    select(matched, unmatched) %>%
    as.matrix()

# Perform the chi-squared test
chisq_test <- chisq.test(contingency_table)

# View the results
chisq_test


s1_aggb <- s1_agg %>%
  mutate(matched_goal = as.numeric(matched_goal)) 

m1_s1 <- brms::brm(
  matched_goal ~ refClass,        # Logistic regression with reference class as predictor
  data = s1_agg,                    # The dataset
  family = bernoulli(),           # Binary outcome model
 # prior = set_prior("normal(0, 1)", class = "b"),  # Prior for coefficients
  iter = 2000,                    # Number of iterations
  chains = 4,                     # Number of MCMC chains
  cores = 4,                      # Number of cores for parallel computation
  seed = 123                      # Set seed for reproducibility
)
# Regression Coefficients: - prior
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept             -0.53      0.12    -0.76    -0.30 1.00     3182     2941
# refClassPercentage    -0.76      0.18    -1.12    -0.41 1.00     2565     2685
# refClassUSD           -1.64      0.21    -2.06    -1.24 1.00     2576     2941
# Regression Coefficients: - no prior
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept             -0.49      0.12    -0.72    -0.27 1.00     3259     2975
# refClassPercentage    -0.81      0.19    -1.18    -0.45 1.00     2364     2585
# refClassUSD           -1.73      0.21    -2.15    -1.32 1.00     2643     2942





m2_s1 <- brms::brm(
  matched_goal ~ refClass + (1|id),       
  data = s1_agg,                    
  family = bernoulli(),           
  #prior = set_prior("normal(0, 1)", class = "b"),  
  iter = 2000,                    
  chains = 4,                     
  cores = 4,                      
  seed = 123                      
)
# Regression Coefficients:
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept             -3.97      0.95    -6.07    -2.38 1.00     1001     1715
# refClassPercentage    -0.54      0.75    -1.97     0.96 1.00     1523     2223
# refClassUSD           -2.26      0.76    -3.74    -0.77 1.00     1729     2581
# Regression Coefficients: - no prior
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept             -2.04      0.97    -4.11    -0.35 1.01      616     1384
# refClassPercentage    -3.16      1.35    -5.97    -0.65 1.00      542     1234
# refClassUSD           -6.84      1.68   -10.42    -3.87 1.01      581     1096




m3_s1 <- brms::brm(
  matched_goal ~ refClass + (1|id) + (1|state), 
  data = s1_agg,                    
  family = bernoulli(),           
  prior = set_prior("normal(0, 1)", class = "b"),  
  iter = 2000,                    #
  chains = 4,                     
  cores = 4,                      
  seed = 123                      
)
# Regression Coefficients:
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept             -4.08      1.05    -6.39    -2.20 1.00      651     1280
# refClassPercentage    -0.52      0.78    -2.05     1.02 1.01      769     1583
# refClassUSD           -2.25      0.78    -3.78    -0.72 1.00     1036     2002


m4_s1 <- brms::brm(
  matched_goal ~ refClass + (1+plan|id) + (1|state), 
  data = s1_agg,                    
  family = bernoulli(),           
  iter = 4000,                    #
  chains = 4,                     
  cores = 4,                      
  seed = 123                      
)
# Regression Coefficients:
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept             -4.24      1.12    -6.60    -2.18 1.00     1280      962
# refClassPercentage    -0.49      0.79    -1.99     1.12 1.00     2347     4012
# refClassUSD           -2.22      0.78    -3.74    -0.71 1.00     2395     4132

m5_s1 <- brms::brm(
  matched_goal ~ refClass + (1+plan|id) + (1|state), 
  data = s1_agg,                    
  family = bernoulli(),           
  iter = 4000,                    #
  chains = 4,                     
  cores = 4,                      
  seed = 123                      
)
# Regression Coefficients:
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept             -2.20      1.15    -4.56     0.02 1.00     1819     2875
# refClassPercentage    -3.34      1.53    -6.59    -0.64 1.00     1139     2377
# refClassUSD           -7.37      1.90   -11.64    -4.13 1.00     1706     3083



```
```{r}
#| eval: FALSE

stanplot(m5_s1)

mcmc_plot(m5_s1, pars = c("b_Intercept","refClassPercentage", "refClassUSD"), regex = FALSE)
mcmc_plot(m5_s1, regex_pars=c('b_*'), regex = FALSE)


m5_s1 |> emmeans(~refClass)
#  refClass   emmean lower.HPD upper.HPD
#  kWh          -2.2      -4.6       0.0
#  Percentage   -5.4      -8.5      -2.9
#  USD          -9.4     -13.4      -6.3
# 
# Point estimate displayed: median 
# Results are given on the logit (not the response) scale. 
# HPD interval probability: 0.95 

m5_s1 |> emmeans(~refClass) |> gather_emmeans_draws() |> 
  ggplot(aes(x=refClass,y=.value,fill=refClass)) +
  stat_dist_pointinterval() + stat_halfeye(alpha=.2) +
  stat_lineribbon(alpha = .25, size = 1, .width = c(.95))


# transform the log-odds to odds





```


## Data checks

```{r}



library(tidyverse)

# for every combination of state, appliance, and refClass, calculate the number of distinct values of family, and of state_avg
s1 |> group_by(state,appliance,refClass) |> 
  summarise(n_distinct_family=n_distinct(family),
            n_distinct_state_avg=n_distinct(state_avg), 
            # paste a string of each distinct value, separated by a comma
            distinct_family=paste(unique(family),collapse=","),
            distinct_state_avg=paste(unique(state_avg),collapse=",")) |>
  filter(n_distinct_family>1 | n_distinct_state_avg>1) 


s1 |> group_by(state,appliance,refClass) |> 
  mutate(n_distinct_family=n_distinct(family),
            n_distinct_state_avg=n_distinct(state_avg), 
            # paste a string of each distinct value, separated by a comma
            distinct_family=paste(unique(family),collapse=","),
            distinct_state_avg=paste(unique(state_avg),collapse=",")) |>
  filter(n_distinct_family>1 | n_distinct_state_avg>1) |> 
  group_by(state,appliance,refClass,family,state_avg) 
  # the count of each unique value of family, and each unique value of state avg
  
 
s1 |> 
    group_by(state, appliance, refClass) |> 
    mutate(n_distinct_family = n_distinct(family),
           n_distinct_state_avg = n_distinct(state_avg), 
           distinct_family = paste(unique(family), collapse = ","),
           distinct_state_avg = paste(unique(state_avg), collapse = ",")) |>
    filter(n_distinct_family > 1 | n_distinct_state_avg > 1,plan=="plan1") |> 
    group_by(state, appliance, refClass, family, state_avg) |> 
    mutate(state_avg_count = n_distinct(state_avg),
           family_count = n()) |> 
    ungroup() |> 
    group_by(state, appliance, refClass, state_avg) |> 
    mutate(state_avg_count = n()) |> 
    distinct(state, appliance, refClass, family, state_avg, family_count, state_avg_count) |> 
  arrange(state,appliance,refClass)



haven::read_sav(here::here("data/Frequency & Probability Study 1 - 3-24-19.sav"))  |> filter(ResponseId=="R_2QMsYuHS385pTj1") -> k
# find if any columns equal 5.26



haven::read_sav(here::here("data/Frequency & Probability Study 1 - 3-24-19.sav")) |>
  filter(ResponseId == "R_vB56XspT1LqhrkB") |>
  # Select columns with non-NA values and not empty strings, handling character and numeric columns separately
  select(
    where(~ is.numeric(.) && !all(is.na(.))),
    where(~ is.character(.) && !all(is.na(.)) && !all(. == ""))
  ) |>
  # Remove columns that start with "AIN"
  select(-starts_with("AIN"))


haven::read_sav(here::here("data/Frequency & Probability Study 1 - 3-24-19.sav"))  |> select_if(~any(. ==11441.0)) |> 
  # filter out any NAs from any column that is left (we don't know the column names)
  filter_all(any_vars(!is.na(.))) |> 
  # retain only cases of 11441.0
  filter_all(any_vars(. == 11441.0)) 



haven::read_sav(here::here("data/Frequency & Probability Study 1 - 3-24-19.sav"))  |> # return the names of any columns that contain 11441.0
  select_if(~any(. ==11441.0)) |> 
  names() |> 
  str_c(collapse=",") |> 
  cat() # P3TEX15

# do the same procedure for each of these values, include a line break after the output from each number
low_freq <- c(5.26, 4534, 340,11667,5.3,400, 29046,5600,5987,34265.0,5600.0	)


# for(val in low_freq) {
#   haven::read_sav(here::here("data/Frequency & Probability Study 1 - 3-24-19.sav")) |>
#     select_if(~any(. == val)) |>
#     names() |>
#     str_c(collapse = ",") |>
#     cat()
#   cat("\n")  # Add line break after each output
# }

low_freq |>
  walk(function(val) {
    cat(val, "\n")  # Print the current value
    haven::read_sav(here::here("data/Frequency & Probability Study 1 - 3-24-19.sav")) |>
      select_if(~any(. == val)) |>
      names() |>
      str_c(collapse = ",") |>
      cat()
    cat("\n\n")  # Add two line breaks before next value
  })




k %>% select_if(~any(is.numeric(.)) & . <10)
haven::read_sav(here::here("data/Frequency & Probability Study 1 - 3-24-19.sav")) |> select(P3TEX15) |> unique()


haven::read_sav(here::here("data/Frequency & Probability Study 1 - 3-24-19.sav")) |> 
  #select(ResponseId, P3TEX15) |> 
  filter(!is.na(P3TEX15))

# A tibble: 2 × 2
#   P3TEX15 `n()`
#     <dbl> <int>
# 1    5.26    10
# 2   NA      242

```

