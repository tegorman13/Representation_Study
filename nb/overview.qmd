---
title: "Results Overview"
execute:
  #echo: false
  warning: false
format:
  html: 
    grid:
      sidebar-width: 220px
      body-width: 1200px
      margin-width: 170px
      gutter-width: 1.0rem
  hugo-md:
    include: true
    html-math-method: mathjax
    output-file: overview_hugo.md
  gfm:
    echo: true
    output-file: overview_gfm.md
---

```{r}

pacman::p_load(dplyr,purrr,tidyr,stringr,here,tibble,ggplot2,gt,knitr,kableExtra,ggh4x,patchwork,lme4,flextable,pander)

options(digits=2, scipen=999, dplyr.summarise.inform=FALSE)
walk(c("fun_plot"), ~ source(here::here(paste0("scripts/", .x, ".R"))))
theme_set(theme_nice())

s1 <- readRDS(here::here("data/s1_processed.rds")) |> 
  filter(!(id %in% readRDS(here::here("data/s1_discrep_ids.rds")))) |> 
  mutate(refClass = factor(refClass, levels=c("kWh","Percentage","USD")))


s2_long <- readRDS(here::here("data/s2_processed.rds")) |> 
  filter(!(id %in% readRDS(here::here("data/s2_discrep_ids.rds")))) |> 
  mutate(refClass = factor(refClass, levels=c("kWh","Percentage","USD")))

state_code_map <- c(
  "CAL" = "California",
  "TEX" = "Texas",
  "COL" = "Colorado",
  "MASS" = "Massachusetts"
)


state_to_code <- state_code_map
code_to_state <- setNames(names(state_code_map), state_code_map)
lookup_code <- function(state) {
  if (state %in% names(state_to_code)) {
    return(state_to_code[[state]])
  } else if (state %in% names(code_to_state)) {
    return(code_to_state[[state]])
  } else {
    return(NA)  # Return NA if not found in either mapping
  }
}

```





### Study 1 Subject Counts

```{r}
#| label: tbl-s1-counts
# total subjects
n_s1 <- s1 |> ungroup() |> summarise(n=n_distinct(id))
n_s1_removed <-  readRDS(here::here("data/s1_discrep_ids.rds")) |> length()

print(paste("Study 1: Total subjects:", n_s1$n, "Removed subjects:", n_s1_removed))



s1 |> group_by(refClass) |> 
    rename("Reference Class" = refClass) |>
    summarise(n=n_distinct(id)) |> 
    pander::pandoc.table(caption="Study 1: Number of unique IDs per condition")


s1 |> group_by(refClass,state) |> 
    rename("Reference Class" = refClass) |>
    summarise(n=n_distinct(id)) |> 
    rowwise() |> 
    mutate(state=lookup_code(state)) |> 
    pivot_wider(names_from=state,values_from=n) |>
    pander::pandoc.table(caption="Study 1: Number of unique IDs per condition by state")


s1 |> group_by(refClass,calc) |> 
    rename("Reference Class" = refClass) |>
    summarise(n=n_distinct(id)) |> 
    pivot_wider(names_from=calc,values_from=n) |>
    pander::pandoc.table(caption="Study 1: Number of unique IDs per condition by calculator use")

prop.table(xtabs(~refClass,s1)) |> kable()
prop.table(xtabs(~refClass+calc,s1)) |> kable()
prop.table(xtabs(~refClass+state,s1)) |> kable()


```







### Study 2 - Subject counts 


```{r}

n_s2 <- s2_long |> ungroup() |> summarise(n=n_distinct(id))
n_s2_removed <-  readRDS(here::here("data/s2_discrep_ids.rds")) |> length()

print(paste("Study 2: Total subjects:", n_s2$n, "Removed subjects:", n_s2_removed))



s2_long |> group_by(refClass) |>
    rename("Reference Class" = refClass) |>
    summarise(n=n_distinct(id)) |> 
    pander::pandoc.table(caption="Study 2: Number of unique IDs per condition")

s2_long |> group_by(refClass,calc) |>
    rename("Reference Class" = refClass) |>
    mutate(calc=case_when(calc=="Calculator" ~ "Used Calculator",
                        calc=="No Calculator" ~ "No Calculator")) |>
    summarise(n=n_distinct(id)) |>
    pivot_wider(names_from=calc,values_from=n) |>
    pander::pandoc.table(caption="Study 2: Number of unique IDs per condition by calculator use")


prop.table(xtabs(~refClass,s2_long)) |> kable()
prop.table(xtabs(~refClass+state,s2_long))
prop.table(xtabs(~refClass+calc,
s2_long |> mutate(calc=case_when(calc=="Calculator" ~ "Used Calculator",
                      calc=="No Calculator" ~ "No Calculator")))) |> kable()
```



## Performance

### Study 1

```{r}
#| fig-width: 12
#| fig-height: 8

s1_agg <- s1 |> 
    filter(appliance !="Total kWh") |> 
    group_by(id,refClass,state,block,plan,calc,edu,pct_goal) |> 
    summarise(total_kWh = sum(value),orig_kWh=sum(family), 
                pct_change = round((orig_kWh-total_kWh)/orig_kWh,3), 
                n_change = sum(value!=family),
                state_p_dif=mean(state_p_dif),
                state_f_dif=mean(state_f_dif),
                n_less_avg = sum(less_avg),
                duration=first(Duration__in_seconds_)) |> 
    mutate(matched_goal = (pct_change == pct_goal), 
                error = pct_change - pct_goal,
                abs_error = abs(error),
                close_match = abs_error <= 0.03)

s1_agg4 <- s1_agg |> group_by(id,refClass) |> 
    summarise(mg=sum(matched_goal),n=n(), pct=mg/n) 


# overall pct of subjects who matched their goal
s1_agg4 |> ungroup() |>
    summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 1: Proportion of participants who matched their goal overall")

# proportion matching vs close match

s1_agg |> pivot_longer(c(matched_goal,close_match),names_to="match_type",values_to="match") |> 
    group_by(id,match_type) |>
    summarise(mg=sum(match),n=n(), pct=mg/n) |>
    group_by(match_type) |>
    summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 1: Proportion of participants who matched their goal or were within 3% of their goal")





# refClass
s1_agg4 |> 
group_by(refClass) |> 
summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 1: Proportion of participants who matched their goal by condition")


```



### Study 2 Performance

```{r}

s2_agg1 <- s2_long |> 
  filter(appliance != "TOTAL") |> 
  group_by(id, state,refClass,pct,pct_goal,plan,rounded) |> 
  summarise(
    total_kWh = sum(value),
    orig_kWh = sum(family),
    pct_change = round((orig_kWh - total_kWh) / orig_kWh, 3),
    state_dif = mean(state_dif),
    .groups = "drop"
  ) |>
  mutate(matched_goal = (pct_change == pct),
  close_match = abs(pct_change-pct)<.03)

s2_agg4 <- s2_agg1|> group_by(id,refClass) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) 


# overall pct of subjects who matched their goal
s2_agg4 |> ungroup() |>
    summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 2: Proportion of participants who matched their goal overall")

# proportion matching vs close match

s2_agg1 |> pivot_longer(c(matched_goal,close_match),names_to="match_type",values_to="match") |> 
    group_by(id,match_type) |>
    summarise(mg=sum(match),n=n(), pct=mg/n) |>
    group_by(match_type) |>
    summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 2: Proportion of participants who matched their goal or were within 3% of their goal")



# refClass only 
s2_agg4 |> 
    group_by(refClass) |> 
    summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 2: Proportion of participants who matched their goal by condition")


# rounded only

s2_agg1 |> group_by(id,rounded) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) |> 
    group_by(rounded) |>
    summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 2: Proportion of participants who matched their goal by rounding condition")


# pct_goal only

s2_agg1 |> group_by(id,pct_goal) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) |> 
    group_by(pct_goal) |>
    summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 2: Proportion of participants who matched their goal by goal condition")



# refClass x rounded

s2_agg1 |> group_by(id, refClass,rounded) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) |> 
    group_by(refClass,rounded) |>
    summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 2: Proportion of participants who matched their goal by condition and rounding")
  


# refClass x pct_goal

s2_agg1 |> group_by(id, refClass,pct_goal) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) |> 
    group_by(refClass,pct_goal) |>
    summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 2: Proportion of participants who matched their goal by condition and goal")



# pct_goal x rounded

s2_agg1 |> group_by(id, pct_goal,rounded) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) |> 
    group_by(pct_goal,rounded) |>
    summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 2: Proportion of participants who matched their goal by goal and rounding")



# pct_goal x rounded x refClass

s2_agg1 |> group_by(id, pct_goal,rounded,refClass) |> 
  summarise(mg=sum(matched_goal),n=n(), pct=mg/n) |> 
    group_by(pct_goal,rounded,refClass) |>
    summarise(
    mean = mean(pct),
    sd = sd(pct),
    n = n(),
    se=sd(pct)/sqrt(n)
) |> pander::pandoc.table(caption="Study 2: Proportion of participants who matched their goal by goal, rounding, and condition")


```



## Group comparison via proportions

### Study 1

```{r}
#| label: tbl-s1-agg

s1_agg <- s1 |> 
    filter(appliance !="Total kWh") |> 
    group_by(id,refClass,state,block,plan,calc,edu,pct_goal) |> 
    summarise(total_kWh = sum(value),orig_kWh=sum(family), 
                pct_change = round((orig_kWh-total_kWh)/orig_kWh,3), 
                n_change = sum(value!=family),
                state_p_dif=mean(state_p_dif),
                state_f_dif=mean(state_f_dif),
                n_less_avg = sum(less_avg),
                duration=first(Duration__in_seconds_)) |> 
    mutate(matched_goal = (pct_change == pct_goal), 
                error = pct_change - pct_goal,
                abs_error = abs(error),
                close_match = abs_error <= 0.03) |>
    ungroup() |> # Add ungroup here
        mutate(
            accuracy_level = factor(
                case_when(
                    abs_error == 0.00 ~ "Exact match",
                    abs_error <= 0.02 ~ "0.01-2% error",
                    abs_error <= 0.15 ~ "2.01-15% error",
                    TRUE ~ "Over 15% error"  # Capture all remaining cases
                ), 
                levels = c("Exact match", "0.01-2% error", "2.01-15% error", "Over 15% error"),
                ordered = TRUE
            )
        ) |> relocate(accuracy_level, .after= "pct_change")



s1_agg4 <- s1_agg |> group_by(id,refClass,calc) |> 
    mutate(n_accuracy = n_distinct(accuracy_level)) |> 
    summarise(mg=sum(matched_goal),n=n(), pct=mg/n,mean_pct_change=mean(pct_change),mean_abs_error=mean(abs_error),n_accuracy=first(n_accuracy)) |> 
    mutate(accuracy_level = factor(
            case_when(
                mean_abs_error < 0.02 ~ "Exact match",
                mean_abs_error <= 0.02 ~ "0.01-2% error",
                mean_abs_error <= 0.15 ~ "2.01-15% error",
                TRUE ~ "Over 15% error"  # Capture all remaining cases
            ), 
            levels = c("Exact match", "0.01-2% error", "2.01-15% error", "Over 15% error"),
            ordered = TRUE
        ))
  



# s1_agg |> arrange(id,accuracy_level) |> 
#   select(id,refClass,state,block,plan,total_kWh,orig_kWh,pct_change,accuracy_level,n_change,matched_goal,error,abs_error) |> print(n=20)

observed_props <- s1_agg |>
  group_by(refClass, accuracy_level) |>
  summarise(n = n()) |>
  group_by(refClass) |>
  mutate(prop = n/sum(n)) |>
  pivot_wider(
    names_from = accuracy_level,
    values_from = c(n, prop)
  )


prop_acc_s1 <- s1_agg %>%
    group_by(refClass, accuracy_level) %>%
    summarise(count = n()) %>%
    group_by(refClass) %>%
    mutate(Probability = count / sum(count)) %>%
    ungroup()



# compute percentage of subjects per accuracy level per group
observed_props_s1 <- s1_agg |>
  group_by(refClass, accuracy_level) |>
  summarise(n = n()) |>
  group_by(refClass) |>
  mutate(prop = n/sum(n)) |>
  mutate(n_prop=paste0(n," (",round(prop*100,1),"%)" ), pct_grp=paste0(round(prop*100,1), "%")) |> ungroup()

observed_props_s1 |> 
  mutate(n_total=sum(n)/4) |> 
  group_by(accuracy_level) |>
  mutate(ns=sum(n)/4) |> 
  mutate(Total = paste0(round(ns/n_total*100,1), "%")) |>
  select('Reference Class'=refClass, 'Accuracy Level'=accuracy_level, '% in Group'=pct_grp, "Combined Groups %" =Total) |>
  pivot_wider(
    names_from = 'Reference Class',
    values_from = c('% in Group')
  ) |> relocate("Combined Groups %" , .after=last_col()) |> 
  pander::pandoc.table(caption="Study 1: Proportion of participants per accuracy level by condition")



# observed_props_s1 |> 
#   select('Reference'=refClass, 'Accuracy Level'=accuracy_level, 'n (% group)'=n_prop) |>
#   pivot_wider(
#     names_from = 'Accuracy Level',
#     values_from = c('n (% group)')
#   ) 


# % of accuracy_level
prop_acc_s1 <- s1_agg %>%
    group_by(refClass, accuracy_level) %>%
    summarise(count = n()) %>%
    group_by(accuracy_level) |>
    mutate(Probability = count / sum(count)) %>%
    ungroup()

# % of entire sample 
prop_acc_s1 <- s1_agg %>%
    group_by(refClass, accuracy_level) %>%
    summarise(count = n()) %>%
    ungroup() |> 
    mutate(Probability = count / sum(count)) %>%
    ungroup()


```


::: {.content-visible when-format="html"}

```{r}
#| label: tbl-s1-interactive



s1_agg4 |> 
    DT::datatable(extensions = 'Buttons',
    options = list(
       dom = 'Blfrtip',
       buttons = list('copy', 'csv', 'excel', 'pdf', 'print'),
      pageLength = 25,
      autoWidth = TRUE
    ),
    filter = 'top', caption="Exp 1. Participant global averages") 


s1_agg |> 
  select(id,refClass,calc,state,plan,pct_change,accuracy_level,n_change,matched_goal,abs_error,total_kWh,orig_kWh) |> 
    group_by(id,refClass,calc) |> 
    mutate(n_accuracy = n_distinct(accuracy_level)) |> 
    mutate(mean_abs_error=mean(abs_error), .after=abs_error) |> 
    mutate(across(where(is.numeric), \(x) round(x, 3))) %>%
    DT::datatable(extensions = 'Buttons',
    options = list(
       dom = 'Blfrtip',
       buttons = list('copy', 'csv', 'excel', 'pdf', 'print'),
      pageLength = 25,
      autoWidth = TRUE
    ),
    filter = 'top', caption="Exp 1. Participant trial level performance") 



s1_agg |> filter(id==124) |> 
  select(id,refClass,state,block,plan,total_kWh,orig_kWh,pct_change,accuracy_level,n_change,matched_goal,abs_error) |> 
  group_by(id) |> mutate(mean_abs_error=mean(abs_error), .after=abs_error) |> 
  pander::pandoc.table(caption="Study 1: Example of participant performance (sbj 124")


```

:::




### Study 2

```{r}
#| label: tbl-s2-agg
#| fig-width: 12

s2_agg1 <- s2_long |> 
  filter(appliance != "TOTAL") |> 
  group_by(id,refClass,calc, state,pct,pct_goal,plan,rounded) |> 
  summarise(
    total_kWh = sum(value),
    orig_kWh = sum(family),
    pct_change = round((orig_kWh - total_kWh) / orig_kWh, 3),
    state_dif = mean(state_dif),
    .groups = "drop"
  ) |>
  mutate(matched_goal = (pct_change == pct),
                error = pct_change - pct,
                abs_error = abs(error)) |> 
      ungroup() |> # Add ungroup here
        mutate(
            accuracy_level = factor(
                case_when(
                    abs_error == 0.00 ~ "Exact match",
                    abs_error <= 0.02 ~ "0.01-2% error",
                    abs_error <= 0.15 ~ "2.01-15% error",
                    TRUE ~ "Over 15% error"  # Capture all remaining cases
                ), 
                levels = c("Exact match", "0.01-2% error", "2.01-15% error", "Over 15% error"),
                ordered = TRUE
            )
        )

s2_agg4 <- s2_agg1 |> group_by(id,refClass,calc) |> 
    mutate(n_accuracy = n_distinct(accuracy_level)) |> 
    summarise(mg=sum(matched_goal),n=n(), pct=mg/n,mean_pct_change=mean(pct_change),mean_abs_error=mean(abs_error),n_accuracy=first(n_accuracy)) |> 
    mutate(accuracy_level = factor(
            case_when(
                mean_abs_error < 0.02 ~ "Exact match",
                mean_abs_error <= 0.02 ~ "0.01-2% error",
                mean_abs_error <= 0.15 ~ "2.01-15% error",
                TRUE ~ "Over 15% error"  # Capture all remaining cases
            ), 
            levels = c("Exact match", "0.01-2% error", "2.01-15% error", "Over 15% error"),
            ordered = TRUE
        ))
  



# s1_agg |> arrange(id,accuracy_level) |> 
#   select(id,refClass,state,block,plan,total_kWh,orig_kWh,pct_change,accuracy_level,n_change,matched_goal,error,abs_error) |> print(n=20)


# confirm that the proportions are with respect to the total number of subjects in each refClass
# 74/.268 = 276; 69*4=276;  38/.138=275;  .435 + .0797 + .21 + .275 = 1


# compute percentage of subjects per accuracy level per group
observed_props_s2 <- s2_agg1 |>
  group_by(refClass, accuracy_level) |>
  summarise(n = n()) |>
  group_by(refClass) |>
  mutate(prop = n/sum(n)) |>
  mutate(n_prop=paste0(n," (",round(prop*100,1),"%)" ), pct_grp=paste0(round(prop*100,1), "%")) |> ungroup()

observed_props_s2 |> 
  mutate(n_total=sum(n)/4) |> 
  group_by(accuracy_level) |>
  mutate(ns=sum(n)/4) |> 
  mutate(Total = paste0(round(ns/n_total*100,1), "%")) |>
  select('Reference Class'=refClass, 'Accuracy Level'=accuracy_level, '% in Group'=pct_grp, "Combined Groups %" =Total) |>
  pivot_wider(
    names_from = 'Reference Class',
    values_from = c('% in Group')
  ) |> relocate("Combined Groups %" , .after=last_col()) |> 
  pander::pandoc.table(caption="Study 1: Proportion of participants per accuracy level by condition")



observed_props_s2 |>  select('Reference'=refClass, 'Accuracy Level'=accuracy_level, 'n (% group)'=n_prop) |>
  pivot_wider(
    names_from = 'Accuracy Level',
    values_from = c('n (% group)')
  )


# % of accuracy_level
prop_acc_s2 <- s2_agg1 %>%
    group_by(refClass, accuracy_level) %>%
    summarise(count = n()) %>%
    group_by(accuracy_level) |>
    mutate(Probability = count / sum(count)) %>%
    ungroup()

  # % of entire sample 
  prop_combo_s2 <- s2_agg1 %>%
      group_by(refClass, accuracy_level) %>%
      summarise(count = n()) %>%
      group_by(refClass) %>%
      mutate(Probability = count / sum(count)) %>%
      ungroup()




 
```


## Study 2 proportion in accuracy plots

```{r}




p1 <- ggplot(prop_combo_s2, aes(x = accuracy_level, y = Probability, fill = refClass)) +
    geom_bar(stat = "identity", position = position_dodge()) +
  scale_y_continuous(labels = scales::percent) +
    labs(title = "Within-Group %'s per Accuracy bin",
        x = "Accuracy Level",
        y = "Percentage of Participants",
        fill = "Reference Class") +
    theme_minimal() 

 p2 <- ggplot(data = s2_agg1, aes(x = accuracy_level, fill = refClass)) +
  geom_bar(position = "dodge", aes(y = (..count..)/sum(..count..))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Combined Participant %'s per bin",
       x = "Accuracy Level",
       y = "Percentage of Participants",
       fill = "Reference Class") +
  theme_minimal()
 
 

 p3 <- ggplot(prop_acc_s2, aes(x = accuracy_level, y = Probability, fill = refClass)) +
    geom_bar(stat = "identity", position = position_dodge()) +
  scale_y_continuous(labels = scales::percent) +
    labs(title = "Aggregate by Accuracy Bin",
        x = "Accuracy Level",
        y = "Percentage of Participants",
        fill = "Reference Class") +
    theme_minimal() 
 
 # combined plots, and unify axes and legends
{ p1 + p2 +p3 + plot_layout(guides = 'collect') & theme(legend.position = 'right') } + plot_annotation(title = "Study 2: Accuracy Level Proportions")

```





## Analysis

### Study 1

```{r}
#| eval: false
#| include: false


pacman::p_load(brms,rstan,bayestestR,emmeans,tidybayes,modelsummary)

# binomial regression on trial level data
s1_br <- brm(
    matched_goal ~ refClass + (1|id),
    data = s1_agg,
    family = bernoulli(),
    cores=4,
    iter=2000,
    control = list(adapt_delta = 0.99),
    file=paste0(here::here("data/model_cache",'s1_br.rds')),
    )

summary(s1_br)

mr_s1 <- as.data.frame(describe_posterior(s1_br, centrality = "Mean"))[, c(1,2,4,5,6)]
colnames(mr_s1) <- c("Term", "Estimate","95% CrI Lower", "95% CrI Upper", "pd")

intercept <- mr_s1$Estimate[mr_s1$Term == "b_Intercept"]

 mr_s1 |>
    mutate(Term = stringr::str_remove(Term, "b_")) |>
    mutate(across(c("Estimate", "95% CrI Lower", "95% CrI Upper"), 
                    \(x) if_else(Term == "Intercept", plogis(x), plogis(x + intercept)))) |>
    mutate(across(where(is.numeric), \(x) round(x, 3))) |>
    mutate(Term = if_else(Term == "Intercept", "Intercept (kWh)", Term)) |>
    tibble::remove_rownames() |>
    kable(booktabs = TRUE)


s1_br2 <- brm(
    close_match ~ refClass + (1|id) + (1|state),
    data = s1_agg,
    family = bernoulli(),
    cores=4,
    iter=2000,
    control = list(adapt_delta = 0.99),
    file=paste0(here::here("data/model_cache",'s1_br2.rds')),
    )
summary(s1_br2)

s1_br2 |> emmeans(~refClass, type="response")



s1_agg <- s1 |> 
    filter(appliance !="Total kWh") |> 
    group_by(id,refClass,state,block,plan,calc,edu,pct_goal) |> 
    summarise(total_kWh = sum(value),orig_kWh=sum(family), 
                pct_change = round((orig_kWh-total_kWh)/orig_kWh,3), 
                n_change = sum(value!=family),
                state_p_dif=mean(state_p_dif),
                state_f_dif=mean(state_f_dif),
                n_less_avg = sum(less_avg),
                duration=first(Duration__in_seconds_)) |> 
    mutate(matched_goal = (pct_change == pct_goal), 
                error = pct_change - pct_goal,
                abs_error = abs(error),
                close_match = abs_error <= 0.03) |>
    ungroup() |> # Add ungroup here
    mutate(
        accuracy_level = factor(
            case_when(
                abs_error <= 0.01 ~ "1% or less",
                abs_error <= 0.05 ~ "5% or less",
                abs_error <= 0.10 ~ "10% or less",
                TRUE ~ "Greater than 10%"  # Capture all remaining cases
            ), 
            levels = c("1% or less", "5% or less", "10% or less", "Greater than 10%"),
            ordered = TRUE
        )
    )


```

## Ordinal Regression alternative

```{r}
#| eval: false
#| include: false


s1_agg <- s1 |> 
    filter(appliance !="Total kWh") |> 
    group_by(id,refClass,state,block,plan,calc,edu,pct_goal) |> 
    summarise(total_kWh = sum(value),orig_kWh=sum(family), 
                pct_change = round((orig_kWh-total_kWh)/orig_kWh,3), 
                n_change = sum(value!=family),
                state_p_dif=mean(state_p_dif),
                state_f_dif=mean(state_f_dif),
                n_less_avg = sum(less_avg),
                duration=first(Duration__in_seconds_)) |> 
    mutate(matched_goal = (pct_change == pct_goal), 
                error = pct_change - pct_goal,
                abs_error = abs(error),
                close_match = abs_error <= 0.03) |>
    ungroup() |> # Add ungroup here
        mutate(
            accuracy_level = factor(
                case_when(
                    abs_error == 0.00 ~ "Exact match",
                    abs_error <= 0.02 ~ "0.01-2% error",
                    abs_error <= 0.10 ~ "2.01-15% error",
                    TRUE ~ "Over 15% error"  # Capture all remaining cases
                ), 
                levels = c("Exact match", "0.01-2% error", "2.01-15% error", "Over 15% error"),
                ordered = TRUE
            )
        )
    # mutate(
    #     accuracy_level = factor(
    #         case_when(
    #             abs_error <= 0.01 ~ "1% or less",
    #             abs_error <= 0.05 ~ "5% or less",
    #             abs_error <= 0.10 ~ "10% or less",
    #             TRUE ~ "Greater than 10%"  # Capture all remaining cases
    #         ), 
    #         levels = c("1% or less", "5% or less", "10% or less", "Greater than 10%"),
    #         ordered = TRUE
    #     )
    # )

# plot accuracy level by refClass

s1_agg |> 
        mutate(
            accuracy_level = factor(
                case_when(
                    abs_error == 0.00 ~ "Exact match",
                    abs_error <= 0.02 ~ "0.01-2% error",
                    abs_error <= 0.10 ~ "2.01-15% error",
                    TRUE ~ "Over 15% error"  # Capture all remaining cases
                ), 
                levels = c("Exact match", "0.01-2% error", "2.01-15% error", "Over 15% error"),
                ordered = TRUE
            )
        ) |>
    ggplot(aes(x=refClass,fill=accuracy_level)) +
    geom_bar(position="fill") +
    labs(title="Study 1: Accuracy Level by Reference Class",
        x="Reference Class",
        y="Proportion",
        fill="Accuracy Level") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))


ordinal_model_s1 <- brm(
  accuracy_level ~ refClass + (1|id) + (1|state),
  data = s1_agg,
  family = cumulative("logit"),
  cores = 4,
  iter = 2000,
  control = list(adapt_delta = 0.99), # Recommended for ordinal models
  prior = c(prior(normal(0, 2), class = "Intercept"),  # Priors for thresholds
            prior(normal(0, 1.5), class = "b")), # Priors for predictors
  file = paste0(here::here("data/model_cache",'s1_ordinal3.rds')) # Cache for efficiency
)


pred_summary <- ordinal_model_s1 |>
    epred_draws(newdata = data.frame(refClass = c("kWh", "Percentage", "USD")),
                ndraws = 1000, re_formula = NA) |>
    group_by(refClass, .category) |>
    summarise(
        mean_prob = mean(.epred),
        lower_ci = quantile(.epred, 0.025),
        upper_ci = quantile(.epred, 0.975)
    )
pred_summary |> pander::pandoc.table(caption="Study 1: Predicted probabilities of accuracy level by reference class")

ggplot(pred_summary, 
       aes(x = refClass, y = mean_prob, fill = .category)) +
  geom_col(position = "stack") +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
                position = position_stack()) +
  labs(x = "Reference Class", 
       y = "Predicted Probability",
       fill = "Accuracy Level",
       title = "Predicted Probabilities of Accuracy Levels by Reference Class") +
  theme_minimal() +
  scale_fill_brewer(palette = "Blues")

# Calculate cumulative probabilities
cum_probs <- pred_summary |>
  group_by(refClass) |>
  arrange(refClass, .category) |>
  mutate(
    cum_prob = cumsum(mean_prob),
    cum_lower = cumsum(lower_ci),
    cum_upper = cumsum(upper_ci)
  )

ggplot(cum_probs, 
    aes(x = refClass, y = cum_prob, color = .category)) +
geom_point(size = 3,position=position_dodge()) +
geom_errorbar(aes(ymin = cum_lower, ymax = cum_upper), 
            width = 0.2,position=position_dodge()) +
labs(x = "Reference Class",
    y = "Cumulative Probability",
    color = "Accuracy Level",
    title = "Cumulative Probabilities of Accuracy Levels") +
theme_minimal() +
scale_color_brewer(palette = "Blues") 

summary_table <- pred_summary |>
  pivot_wider(
    names_from = .category,
    values_from = c(mean_prob, lower_ci, upper_ci)
  ) |>
  kable(digits = 3)

print(summary_table)

# Convert log-odds to odds ratios
posterior_samples <- as.data.frame(ordinal_model_s1)
odds_ratios <- data.frame(
  Percentage_vs_kWh = exp(posterior_samples$b_refClassPercentage),
  USD_vs_kWh = exp(posterior_samples$b_refClassUSD)
)

# Calculate summary statistics
odds_ratio_summary <- data.frame(
  comparison = c("Percentage vs kWh", "USD vs kWh"),
  odds_ratio = c(mean(odds_ratios$Percentage_vs_kWh),
                 mean(odds_ratios$USD_vs_kWh)),
  ci_lower = c(quantile(odds_ratios$Percentage_vs_kWh, 0.025),
               quantile(odds_ratios$USD_vs_kWh, 0.025)),
  ci_upper = c(quantile(odds_ratios$Percentage_vs_kWh, 0.975),
               quantile(odds_ratios$USD_vs_kWh, 0.975))
)


# Plot predicted probabilities
ggplot(pred_summary, aes(x = refClass, y = mean_prob, fill = .category)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci),
                position = position_dodge(width = 0.9), width = 0.2) +
  labs(y = "Predicted Probability", x = "Reference Class", fill = "Accuracy Level") +
  ggtitle("Study 1: Predicted Probabilities of Accuracy Level by Reference Class") +
  theme_minimal()













```


#### Frequentist alternative

```{r}
#| eval: false
#| include: false

s1_glm <- glm(matched_goal ~ refClass, data = s1_agg, family = binomial())
summary(s1_glm)

# Odds Ratios and Confidence Intervals
exp(cbind(Odds_Ratio = coef(s1_glm), confint(s1_glm)))

# Chi-Square Test for Proportions in Study 1
s1_table <- table(s1_agg$refClass, s1_agg$matched_goal)
chisq.test(s1_table)

```

### Study 2

```{r}
#| eval: false
#| include: false
# binomial regression on trial level data

s2_br_3 <- brm(
    matched_goal ~ refClass+rounded+pct_goal + (1|id) + (1|state),
    data = s2_agg1,
    family = bernoulli(),
    cores=4,
    iter=2000,
    control = list(adapt_delta = 0.99),
    file=paste0(here::here("data/model_cache",'s2_br_3.rds')),
    )

summary(s2_br_3)


mr_s2_3 <- as.data.frame(describe_posterior(s2_br_3, centrality = "Mean"))[, c(1,2,4,5,6)]
colnames(mr_s2_3) <- c("Term", "Estimate","95% CrI Lower", "95% CrI Upper", "pd")


 mr_s2_3 |>
    mutate(Term = stringr::str_remove(Term, "b_")) |>
    mutate(across(where(is.numeric), \(x) round(x, 3))) |>
    mutate(Term = if_else(Term == "Intercept", "Intercept (kWh)", Term)) |>
    tibble::remove_rownames() |>
    kable(booktabs = TRUE)



s2_br2_3 <- brm(
    close_match ~ refClass+rounded+pct_goal + (1|id) + (1|state),
    data = s2_agg1,
    family = bernoulli(),
    cores=4,
    iter=2000,
    control = list(adapt_delta = 0.99),
    file=paste0(here::here("data/model_cache",'s2_br2_3.rds')),
    )

summary(s2_br2_3)

#s2_br2_3 |> emmeans(~refClass, type="response")

mr_s2_3_2 <- as.data.frame(describe_posterior(s2_br2_3, centrality = "Mean"))[, c(1,2,4,5,6)]
colnames(mr_s2_3_2) <- c("Term", "Estimate","95% CrI Lower", "95% CrI Upper", "pd")


mr_s2_3_2 |>
    mutate(Term = stringr::str_remove(Term, "b_")) |>
    mutate(across(where(is.numeric), \(x) round(x, 3))) |>
    mutate(Term = if_else(Term == "Intercept", "Intercept (kWh)", Term)) |>
    tibble::remove_rownames() |>
    kable(booktabs = TRUE)

```



```{r}
#| eval: false
#| include: false
#| 
s2_glm <- glm(matched_goal ~ refClass + rounded + pct_goal, data = s2_agg1, family = binomial())
summary(s2_glm)

# Odds Ratios and Confidence Intervals
exp(cbind(Odds_Ratio = coef(s2_glm), confint(s2_glm)))

# Chi-Square Test for Proportions in Study 2
s2_table <- table(s2_agg1$refClass, s2_agg1$matched_goal)
chisq.test(s2_table)

```