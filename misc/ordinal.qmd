---
title: "Ordinal Models"
execute:
  #echo: false
  eval: false
  warning: false
format:
  html: 
    grid:
      sidebar-width: 220px
      body-width: 1200px
      margin-width: 170px
      gutter-width: 1.0rem
  hugo-md:
    include: true
    html-math-method: mathjax
    output-file: ordinal_hugo.md
  gfm:
    echo: true
    output-file: ordinal.md
---

## Ordinal Regression alternative

```{r}

pacman::p_load(dplyr,purrr,tidyr,here,tibble,stringr,brms,rstan,bayestestR,emmeans,tidybayes,modelsummary,
               ggplot2,gt,knitr,kableExtra,ggh4x,lme4,flextable,pander,marginaleffects,ggstance)
options(digits=2, scipen=999, dplyr.summarise.inform=FALSE)
walk(c("fun_plot"), ~ source(here::here(paste0("scripts/", .x, ".R"))))
theme_set(theme_nice())
options(brms.backend="cmdstanr",mc.cores=4)

# s1 <- readRDS(here::here("data/s1_processed.rds")) |> filter(!(id %in% readRDS(here::here("data/s1_discrep_ids.rds"))))
# s2_long <- readRDS(here::here("data/s2_processed.rds")) |> filter(!(id %in% readRDS(here::here("data/s2_discrep_ids.rds"))))

s1 <- readRDS(here::here("data/s1_processed.rds")) |> 
  filter(!(id %in% readRDS(here::here("data/s1_discrep_ids.rds")))) |> 
  filter(!(id %in% readRDS(here::here("data/s1_grp_outlier_ids.rds")))) |>
  mutate(refClass = factor(refClass, levels=c("kWh","Percentage","USD")))

s2_long <- readRDS(here::here("data/s2_processed.rds")) |> 
  filter(!(id %in% readRDS(here::here("data/s2_discrep_ids.rds")))) |> 
  filter(!(id %in% readRDS(here::here("data/s2_grp_outlier_ids.rds"))) ) |>
  mutate(refClass = factor(refClass, levels=c("kWh","Percentage","USD")))

```


## Proportions in aggregate data

```{r}
s1_agg <- s1 |> 
    filter(appliance !="Total kWh") |> 
    group_by(id,refClass,state,block,plan,edu,pct_goal,calc) |> 
    summarise(total_kWh = sum(value),orig_kWh=sum(family), 
                pct_change = abs(round((orig_kWh-total_kWh)/orig_kWh,3)), 
                n_change = sum(value!=family),
                state_p_dif=mean(state_p_dif),
                state_f_dif=mean(state_f_dif),
                n_less_avg = sum(less_avg),
                duration=first(Duration__in_seconds_)) |> 
    mutate(matched_goal = (pct_change == pct_goal), 
                error = pct_change - pct_goal,
                abs_error = abs(error),
                log_abs_error=log(abs(error)+.007), 
                close_match = abs_error <= 0.02) |>
    ungroup() |> # Add ungroup here
        mutate(
            accuracy_level = factor(
                case_when(
                    abs_error == 0.00 ~ "Exact match",
                    abs_error <= 0.05 ~ "0.01-5% error",
                    TRUE ~ "Over 5% error"  # Capture all remaining cases
                ), 
                levels = c("Exact match", "0.01-5% error", "Over 5% error"),
                ordered = TRUE
            )
        ) |> relocate(accuracy_level, .after= "pct_change")



s1_agg4 <- s1_agg |> group_by(id,refClass,calc) |> 
    mutate(n_accuracy = n_distinct(accuracy_level)) |> 
    summarise(
    mg=sum(matched_goal),
    mgc=sum(close_match),
    n=n(), 
    pct=mg/n,
    pct_close=mgc/n,
    mean_pct_change=mean(pct_change),
    mean_abs_error=mean(abs_error),
    mean_log_abs_error=mean(log_abs_error),
    n_accuracy=first(n_accuracy)) |> 
    mutate(accuracy_level = factor(
            case_when(
                mean_abs_error < 0.02 ~ "Exact match",
                mean_abs_error <= 0.05 ~ "0.01-5% error",
                TRUE ~ "Over 5% error"  # Capture all remaining cases
            ), 
            levels = c("Exact match", ".01-5% error", "Over 5% error"),
            ordered = TRUE
        ))
  

ggplot(data = s1_agg, aes(x = accuracy_level, fill = refClass)) +
  geom_bar(position = "dodge", aes(y = (..count..)/sum(..count..))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Accuracy Levels by Reference Class",
       x = "Accuracy Level",
       y = "Percentage of Participants",
       fill = "Reference Class") +
  theme_minimal()

observed_props <- s1_agg |>
  group_by(refClass, accuracy_level) |>
  summarise(n = n()) |>
  group_by(refClass) |>
  mutate(prop = n/sum(n)) |>
  pivot_wider(
    names_from = accuracy_level,
    values_from = c(n, prop)
  )

  # Calculate proportions
prop_acc_s1 <- s1_agg %>%
    group_by(refClass, accuracy_level) %>%
    summarise(count = n()) %>%
    group_by(refClass) %>%
    mutate(Probability = count / sum(count)) %>%
    ungroup()

# Plot
ggplot(prop_acc_s1, aes(x = accuracy_level, y = Probability, fill = refClass)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    labs(title = "Distribution of Accuracy Levels by Reference Class",
        x = "Accuracy Level",
        y = "Probability",
        fill = "Reference Class") +
    theme_minimal() +
    scale_fill_brewer(palette = "Set1")


```



## Fit Ordinal model accuracy_level ~ refClass + (1|id) + (1|state)
```{r}





ordinal_model_s1 <- brm(
  accuracy_level ~ refClass + (1|id) + (1|state),
  data = s1_agg,
  family = cumulative("logit"),
  cores = 4,
  iter = 2000,
  control = list(adapt_delta = 0.99), # Recommended for ordinal models
  prior = c(prior(normal(0, 2), class = "Intercept"),  # Priors for thresholds
            prior(normal(0, 1.5), class = "b")), # Priors for predictors
  file = paste0(here::here("data/model_cache",'s1_ordinal3.rds')) # Cache for efficiency
)

summary(ordinal_model_s1)

#ordinal_model_s1 |> emmeans(~refClass, type="response")

pp_check(ordinal_model_s1)

describe_posterior(ordinal_model_s1, centrality = "Mode") |> 
  filter(stringr::str_detect(Parameter, "b_")) |> 
  mutate(Parameter = stringr::str_remove(Parameter, "b_")) |> 
  mutate(across(where(is.numeric), round, 3)) |> 
  kable(booktabs = TRUE)


# Get predicted probabilities
pred_summary <- ordinal_model_s1 |>
    epred_draws(newdata = data.frame(refClass = c("kWh", "Percentage", "USD")),
                ndraws = 1000, re_formula = NA) |>
    group_by(refClass, .category) |>
    summarise(
        mean_prob = mean(.epred),
        lower_ci = quantile(.epred, 0.025),
        upper_ci = quantile(.epred, 0.975)
    )
pred_summary |> pander::pandoc.table(caption="Study 1: Predicted probabilities of accuracy")


# Convert log-odds to odds ratios
posterior_samples <- as.data.frame(ordinal_model_s1)
odds_ratios <- data.frame(
  Percentage_vs_kWh = exp(posterior_samples$b_refClassPercentage),
  USD_vs_kWh = exp(posterior_samples$b_refClassUSD)
)

# Calculate summary statistics
odds_ratio_summary <- data.frame(
  comparison = c("Percentage vs kWh", "USD vs kWh"),
  odds_ratio = c(mean(odds_ratios$Percentage_vs_kWh),
                 mean(odds_ratios$USD_vs_kWh)),
  ci_lower = c(quantile(odds_ratios$Percentage_vs_kWh, 0.025),
               quantile(odds_ratios$USD_vs_kWh, 0.025)),
  ci_upper = c(quantile(odds_ratios$Percentage_vs_kWh, 0.975),
               quantile(odds_ratios$USD_vs_kWh, 0.975))
)


odds_ratio_summary |> kable()
# |comparison        | odds_ratio| ci_lower| ci_upper|
# |:-----------------|----------:|--------:|--------:|
# |Percentage vs kWh |        2.3|     0.62|      6.2|
# |USD vs kWh        |       14.1|     4.08|     38.0|


odds_ratio_summary |> pander::pandoc.table(caption="Study 1: Odds ratios of accuracy")


# Plot predicted probabilities
ggplot(pred_summary, aes(x = refClass, y = mean_prob, fill = .category)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci),
                position = position_dodge(width = 0.9), width = 0.2) +
  labs(y = "Predicted Probability", x = "Reference Class", fill = "Accuracy Level") +
  ggtitle("Study 1: Predicted Probabilities of Accuracy Level by Reference Class") +
  theme_minimal()

```


|comparison        | odds_ratio| ci_lower| ci_upper|
|:-----------------|----------:|--------:|--------:|
|Percentage vs kWh |        2.3|     0.62|      6.2|
|USD vs kWh        |       14.1|     4.08|     38.0|


## S1  posterior predictive checks

```{r}



bayesplot::color_scheme_set(wes_palettes[1]$BottleRocket1[1:6])

pp_check(ordinal_model_s1, type = "bars", ndraws = 1000, fatten = 2) +
    scale_x_continuous("y", breaks = 1:7) +
    scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
    ggtitle("Data with posterior predictions",
            subtitle = "N = 100") 

pp_check(ordinal_model_s1, type = "bars_grouped", group="refClass", fatten = 2) +
    scale_x_continuous("y", breaks = 1:7) +
    scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
    ggtitle("Data with posterior predictions",
            subtitle = expression(list(italic(N[A])==44, italic(N[B])==44))) +
    theme(legend.background = element_blank(),
            legend.position = c(.9, .75))




f <- fitted(ordinal_model_s1,newdata_pred <- expand.grid(
    refClass = c("kWh", "Percentage", "USD"),
    id = unique(s1_agg$id),
    state = unique(s1_agg$state)
    ))


# Create new_data with one id and state
new_data <- expand.grid(
  refClass = c("kWh", "Percentage", "USD"),
  id = unique(s1_agg$id)[1],      # Take first id
  state = unique(s1_agg$state)[1] # Take first state
)


f_df <- as.data.frame.table(f) |>
  rename(Probability = Freq) |>
  # Extract Y levels from the Var3 column
  mutate(Y = str_extract(Var3, "(?<=P\\(Y = ).*(?=\\))")) |>
  # Join with new_data using crossing instead of bind_cols
  crossing(new_data) |>
  # Select and arrange columns as needed
  select(refClass, id, state, Y, Probability)

```

## Comparing Marginal vs Conditional Predictions

```{r}

# Create newdata with all necessary variables
newdata_pred <- expand.grid(
  refClass = c("kWh", "Percentage", "USD"),
  id = unique(s1_agg$id),
  state = unique(s1_agg$state)
)

# Population-level predictions
pred_probs_marginal <- ordinal_model_s1 |>
  epred_draws(
    newdata = data.frame(refClass = c("kWh", "Percentage", "USD")),
    ndraws = 1000, 
    re_formula = NA
  )

# Conditional predictions (including random effects)
pred_probs_conditional <- ordinal_model_s1 |>
  epred_draws(
    newdata = newdata_pred,
    ndraws = 1000, 
    re_formula = NULL
  )

# Compare the two approaches
summary_comparison <- bind_rows(
    pred_probs_marginal |> 
        group_by(refClass, .category) |>
        summarise(
        mean_prob = mean(.epred),
        sd_prob = sd(.epred),
        lower_ci = quantile(.epred, 0.025),
        upper_ci = quantile(.epred, 0.975),
        .groups = 'drop'
        ) |>
        mutate(type = "Marginal"),
    
    pred_probs_conditional |> 
        group_by(refClass, .category) |>
        summarise(
        mean_prob = mean(.epred),
        sd_prob = sd(.epred),
        lower_ci = quantile(.epred, 0.025),
        upper_ci = quantile(.epred, 0.975),
        .groups = 'drop'
        ) |>
        mutate(type = "Conditional")
)

# View the comparison
summary_comparison |>
  arrange(type, refClass, .category) |>
  kable(digits = 3)

# Visualize the comparison
ggplot(summary_comparison, 
        aes(x = .category, y = mean_prob, fill = refClass)) +
    geom_col(position = position_dodge()) +
    geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
            position = position_dodge(width = 0.8)) +
    facet_wrap(~type) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(title = "Comparing Marginal vs Conditional Predictions",
        x = "Accuracy Level",
        y = "Predicted Probability")
```



## Individual Differences in Predictions

```{r}
# Extract random effects for subjects with corrected ID handling
ranef_draws <- ordinal_model_s1 |>
  spread_draws(r_id[id,term]) |>
  mutate(id = as.integer(as.character(id))) # Convert factor to integer

# Get subject-specific adjustments
subject_adjustments <- ranef_draws |>
  group_by(id) |>
  summarise(
    mean_adj = mean(r_id),
    lower = quantile(r_id, 0.025),
    upper = quantile(r_id, 0.975)
  )

# Get reference class for each subject
subject_refclass <- s1_agg |>
  group_by(id) |>
  summarise(refClass = first(refClass))

# Combine adjustments with reference class
subject_plot_data <- subject_adjustments |>
  left_join(subject_refclass, by = "id")

# Create caterpillar plot
ggplot(subject_plot_data, 
       aes(x = reorder(factor(id), mean_adj), 
           y = mean_adj, 
           color = refClass)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower, ymax = upper), alpha = 0.5) +
  coord_flip() +
  facet_wrap(~refClass, scales = "free_y") +
  theme_minimal() +
  labs(title = "Subject-Level Random Effects by Reference Class",
       y = "Subject-Specific Adjustment",
       x = "Subject ID") +
  theme(legend.position = "none")

# Density plot of random effects by condition
ggplot(subject_plot_data, 
       aes(x = mean_adj, fill = refClass)) +
  geom_density(alpha = 0.5) +
  theme_minimal() +
  labs(title = "Distribution of Subject-Level Random Effects by Reference Class",
       x = "Subject-Specific Adjustment",
       y = "Density")

# Summary statistics by condition
random_effects_summary <- subject_plot_data |>
  group_by(refClass) |>
  summarise(
    n = n(),
    mean_adjustment = mean(mean_adj),
    sd_adjustment = sd(mean_adj),
    median_adjustment = median(mean_adj),
    q25 = quantile(mean_adj, 0.25),
    q75 = quantile(mean_adj, 0.75)
  )

print(random_effects_summary)



pop_preds <- ordinal_model_s1 |>
    epred_draws(
        newdata = data.frame(refClass = c("kWh", "Percentage", "USD")),
        ndraws = 1000, 
        re_formula = NA
    ) |>
    group_by(refClass, .category) |>
    summarise(
        pop_mean = mean(.epred),
        pop_lower = quantile(.epred, 0.025),
        pop_upper = quantile(.epred, 0.975)
    )

# Get subject-specific predictions
subject_preds <- ordinal_model_s1 |>
    epred_draws(
        newdata = s1_agg,
        ndraws = 100  # fewer draws for computational efficiency
    ) |>
    group_by(id, refClass, .category) |>
    summarise(
        subj_mean = mean(.epred)
    )


# Plot 1: Population effects with subject-specific points
ggplot() +
    # Add subject-specific points
    geom_jitter(data = subject_preds,
                aes(x = .category, y = subj_mean, color = refClass),
                alpha = 0.2, width = 0.2, height = 0) +
    # Add population-level effects
    geom_point(data = pop_preds,
                aes(x = .category, y = pop_mean, fill = refClass),
                size = 3, shape = 21, color = "black") +
    geom_errorbar(data = pop_preds,
                aes(x = .category, ymin = pop_lower, ymax = pop_upper),
                width = 0.2) +
    facet_wrap(~refClass) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(title = "Population-Level Effects with Subject-Specific Predictions",
        x = "Accuracy Level",
        y = "Predicted Probability")

# Plot 2: Violin plot with population effects
ggplot() +
    # Add violin plot of subject-specific effects
    geom_violin(data = subject_preds,
                aes(x = .category, y = subj_mean, fill = refClass),
                alpha = 0.3) +
    # Add population-level points
    geom_point(data = pop_preds,
                aes(x = .category, y = pop_mean),
                size = 3, color = "black") +
    geom_errorbar(data = pop_preds,
                aes(x = .category, ymin = pop_lower, ymax = pop_upper),
                width = 0.2) +
    facet_wrap(~refClass) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(title = "Distribution of Subject-Specific Effects with Population Estimates",
        x = "Accuracy Level",
        y = "Predicted Probability")

# Plot 3: Subject deviations from population mean
subject_deviations <- subject_preds |>
    left_join(pop_preds, by = c("refClass", ".category")) |>
    mutate(deviation = subj_mean - pop_mean)

ggplot(subject_deviations,
        aes(x = deviation, fill = refClass)) +
    geom_density(alpha = 0.5) +
    geom_vline(xintercept = 0, linetype = "dashed") +
    facet_grid(refClass ~ .category) +
    theme_minimal() +
    labs(title = "Subject Deviations from Population Mean",
        x = "Deviation from Population Mean",
        y = "Density")

# Plot 4: Ridgeline plot of subject effects
library(ggridges)
ggplot(subject_preds,
        aes(x = subj_mean, y = .category, fill = refClass)) +
    geom_density_ridges(alpha = 0.5) +
    geom_vline(data = pop_preds,
                aes(xintercept = pop_mean),
                linetype = "dashed") +
    facet_wrap(~refClass) +
    theme_minimal() +
    labs(title = "Distribution of Subject-Specific Effects by Accuracy Level",
        x = "Predicted Probability",
        y = "Accuracy Level")
```


## Alt s1 visual of predicted probs

```{r}

predicted_probs_s1 <- ordinal_model_s1 %>%
    # gather draws that contain refClass ("b_refClassPercentage"    "b_refClassUSD"  )
    gather_draws(b_refClassPercentage, b_refClassUSD) %>%
    mutate(refClass = case_when(
    str_detect(.variable, "Percentage") ~ "Percentage",
    str_detect(.variable, "USD") ~ "USD",
    TRUE ~ "kWh"
  )) %>%
    group_by(refClass) %>%
    summarise(effect = mean(.value)) %>%
    mutate(
        group = refClass,
        prob_exact = plogis(effect + (-1.85)),
        prob_0_2 = plogis(effect + 0.22) - plogis(effect + (-1.85)),
        prob_2_15 = plogis(effect + 2.86) - plogis(effect + 0.22),
        prob_over15 = 1 - plogis(effect + 2.86)
    ) %>%
    pivot_longer(
        cols = starts_with("prob"),
        names_to = "Accuracy_Level",
        values_to = "Probability"
    ) %>%
    mutate(
        Accuracy_Level = recode(Accuracy_Level,
                                "prob_exact" = "Exact match",
                                "prob_0_2" = "0.01-2% error",
                                "prob_2_15" = "2.01-15% error",
                                "prob_over15" = "Over 15% error")
    )



ggplot(predicted_probs_s1, aes(x = Accuracy_Level, y = Probability, fill = refClass)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Predicted Probabilities of Accuracy Levels by Reference Class",
       x = "Accuracy Level",
       y = "Probability",
       fill = "Reference Class") +
  theme_minimal()

```


## s1 probit 

```{r}

ordinal_model_s1_prb <- brm(
  accuracy_level ~ refClass + (1|id) + (1|state),
  data = s1_agg,
  family = cumulative("probit"),
  cores = 4,
  iter = 2000,
  control = list(adapt_delta = 0.99), # Recommended for ordinal models
  prior = c(prior(normal(0, 3), class = "Intercept"),  # Priors for thresholds
            prior(normal(0, 2), class = "b")), # Priors for predictors
  file = paste0(here::here("data/model_cache",'s1_ordinal_probit1.rds')) # Cache for efficiency
)

summary(ordinal_model_s1_prb)

pp_check(ordinal_model_s1_prb, type = "bars_grouped", group="refClass", fatten = 2) +
    scale_x_continuous("y", breaks = 1:7) +
    scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
    ggtitle("Data with posterior predictions",
            subtitle = expression(list(italic(N[A])==44, italic(N[B])==44))) +
    theme(legend.background = element_blank(),
            legend.position = c(.9, .75))

loo_logit <- loo(ordinal_model_s1)
loo_probit <- loo(ordinal_model_s1_prb)
loo_compare(loo_logit, loo_probit)

waic(ordinal_model_s1)
waic(ordinal_model_s1_prb)

# compare
rstanarm::loo_compare(loo_logit, loo_probit)


# Obtain predicted probabilities
predicted_probs_s1 <- ordinal_model_s1_prb %>%
    gather_draws(b_refClassPercentage, b_refClassUSD) %>%
    mutate(refClass = case_when(
        str_detect(.variable, "Percentage") ~ "Percentage",
        str_detect(.variable, "USD") ~ "USD",
        TRUE ~ "kWh"
    )) %>%
    group_by(refClass) %>%
    summarise(effect = mean(.value)) %>%
    mutate(
        group = refClass,
        prob_exact = plogis(effect + (-1.85)),
        prob_0_2 = plogis(effect + 0.22) - plogis(effect + (-1.85)),
        prob_2_15 = plogis(effect + 2.86) - plogis(effect + 0.22),
        prob_over15 = 1 - plogis(effect + 2.86)
    ) %>%
    pivot_longer(
        cols = starts_with("prob"),
        names_to = "Accuracy_Level",
        values_to = "Probability"
    ) %>%
    mutate(
        Accuracy_Level = recode(Accuracy_Level,
                                "prob_exact" = "Exact match",
                                "prob_0_2" = "0.01-2% error",
                                "prob_2_15" = "2.01-15% error",
                                "prob_over15" = "Over 15% error")
    )

    # Plot predicted probabilities
    ggplot(predicted_probs_s1, aes(x = Accuracy_Level, y = Probability, fill = refClass)) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(title = "Predicted Probabilities of Accuracy Levels by Reference Class",
        x = "Accuracy Level",
        y = "Probability",
        fill = "Reference Class") +
    theme_minimal()


pred_data <- data.frame(
  refClass = c("kWh", "Percentage", "USD"),
  id = unique(s1_agg$id)[1],      # Take first id
  state = unique(s1_agg$state)[1] # Take first state
)

# Predicted probabilities from logit model
pred_probs_logit <- posterior_epred(ordinal_model_s1, newdata = pred_data, re_formula = NA)

# Predicted probabilities from probit model
pred_probs_probit <- posterior_epred(ordinal_model_s1_prb, newdata = pred_data, re_formula = NA)

# Compare predicted probabilities
mean_pred_logit <- apply(pred_probs_logit, 2, mean)
mean_pred_probit <- apply(pred_probs_probit, 2, mean)

comparison <- data.frame(
  Reference_Class = pred_data$refClass,
  Mean_Prob_Logit = mean_pred_logit,
  Mean_Prob_Probit = mean_pred_probit
)

print(comparison)


```




# Study 2

```{r}


s2_agg <- s2_long |> 
  filter(appliance != "TOTAL") |> 
  group_by(id,refClass,calc, state,pct,pct_goal,plan,rounded) |> 
  summarise(
    total_kWh = sum(value),
    orig_kWh = sum(family),
    pct_change = round((orig_kWh - total_kWh) / orig_kWh, 3),
    state_dif = mean(state_dif),
    .groups = "drop"
  ) |>
  mutate(
    matched_goal = (pct_change == pct),
    close_match = abs(pct_change - pct) <= 0.02,
                error = pct_change - pct,
                abs_error = abs(error),
                log_abs_error=log(abs(error)+.007)) |> 
      ungroup() |> 
        mutate(
            accuracy_level = factor(
                case_when(
                    abs_error == 0.00 ~ "Exact match",
                    abs_error <= 0.05 ~ "0.01-5% error",
                    TRUE ~ "Over 5% error"  # Capture all remaining cases
                ), 
                levels = c("Exact match","0.01-5% error", "Over 5% error"),
                ordered = TRUE
            )
        )

s2_agg4 <- s2_agg |> group_by(id,refClass,calc) |> 
    mutate(n_accuracy = n_distinct(accuracy_level)) |> 
    summarise(
    mg=sum(matched_goal),
    mgc=sum(close_match),
    n=n(), 
    pct=mg/n,
    pct_close=mgc/n,
    mean_pct_change=mean(pct_change),
    mean_abs_error=mean(abs_error),
    mean_log_abs_error=mean(log_abs_error),
    n_accuracy=first(n_accuracy)) |> 
    mutate(accuracy_level = factor(
            case_when(
                mean_abs_error < 0.02 ~ "Exact match",
                mean_abs_error <= 0.05 ~ ".01-5% error",
                TRUE ~ "Over 5% error"  # Capture all remaining cases
            ), 
            levels = c("Exact match", "01-5% error", "Over 5% error"),
            ordered = TRUE
        ))




ggplot(data = s2_agg, aes(x = accuracy_level, fill = refClass)) +
  geom_bar(position = "dodge", aes(y = (..count..)/sum(..count..))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Accuracy Levels by Reference Class",
       x = "Accuracy Level",
       y = "Percentage of Participants",
       fill = "Reference Class") +
  theme_minimal()

observed_props2 <- s2_agg |>
  group_by(refClass, accuracy_level) |>
  summarise(n = n()) |>
  group_by(refClass) |>
  mutate(prop = n/sum(n)) |>
  pivot_wider(
    names_from = accuracy_level,
    values_from = c(n, prop)
  )

  # Calculate proportions
prop_acc_s2 <- s2_agg %>%
    group_by(refClass, accuracy_level) %>%
    summarise(count = n()) %>%
    group_by(refClass) %>%
    mutate(Probability = count / sum(count)) %>%
    ungroup()

# Plot
ggplot(prop_acc_s2, aes(x = accuracy_level, y = Probability, fill = refClass)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    labs(title = "Distribution of Accuracy Levels by Reference Class",
        x = "Accuracy Level",
        y = "Probability",
        fill = "Reference Class") +
    theme_minimal() +
    scale_fill_brewer(palette = "Set1")




ggplot(data = s2_agg, aes(x = accuracy_level, fill = refClass)) +
  geom_bar(position = "dodge", aes(y = (..count..)/sum(..count..))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Accuracy Levels by Reference Class",
       x = "Accuracy Level",
       y = "Percentage of Participants",
       fill = "Reference Class") +
  theme_minimal() + facet_wrap(~rounded+pct_goal)


prop4_acc_s2 <- s2_agg %>%
    group_by(refClass, accuracy_level,rounded,pct_goal) %>%
    summarise(count = n()) %>%
    group_by(refClass) %>%
    mutate(Probability = count / sum(count)) %>%
    ungroup()

# Plot


s2_agg %>%
    group_by( accuracy_level,rounded) %>%
    summarise(count = n()) %>%
    group_by(rounded) %>%
    mutate(Probability = count / sum(count)) %>%
    ungroup()


ggplot(prop4_acc_s2, aes(x = accuracy_level, y = Probability, fill = refClass)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    labs(title = "Distribution of Accuracy Levels by Reference Class",
        x = "Accuracy Level",
        y = "Probability",
        fill = "Reference Class") +
    theme_minimal() +
    scale_fill_brewer(palette = "Set1") + facet_wrap(~rounded+pct_goal)



ggplot(prop4_acc_s2, aes(x = accuracy_level, y = Probability, fill = refClass)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    labs(title = "Distribution of Accuracy Levels by Reference Class",
        x = "Accuracy Level",
        y = "Probability",
        fill = "Reference Class") +
    theme_minimal() +
    scale_fill_brewer(palette = "Set1") 


```


# no interaction model used in MPA
```{r}

s2_agg <- s2_agg %>%
  mutate(
    refClass = factor(refClass, levels = c("kWh", "Percentage", "USD")),
    rounded = factor(rounded, levels = c("Not Rounded", "Rounded")),
    pct_goal = factor(pct_goal, levels = c("10%", "15%"))
  )



ordinal_model_s2_probit <- brm(
  accuracy_level ~ refClass +rounded+pct_goal + (1|id)+ (1|state),
  data = s2_agg,
  family = cumulative("probit"),
  cores = 4,
  iter = 2000,
  control = list(adapt_delta = 0.99), # Recommended for ordinal models
  prior = c(prior(normal(0, 2), class = "Intercept"),  # Priors for thresholds
            prior(normal(0, 2), class = "b")), # Priors for predictors
  file = paste0(here::here("data/model_cache",'s2_op.rds')) # Cache for efficiency
)

summary(ordinal_model_s2_probit)
# Regression Coefficients:
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept[1]          -1.12      0.38    -1.88    -0.37 1.01      686     1070
# Intercept[2]          -0.28      0.38    -1.04     0.47 1.01      693     1085
# Intercept[3]           1.81      0.38     1.04     2.56 1.01      702     1248
# refClassPercentage     0.58      0.45    -0.32     1.49 1.01      446      741
# refClassUSD            1.19      0.47     0.29     2.11 1.01      583     1087
# roundedRounded        -0.37      0.10    -0.57    -0.17 1.00     5613     2928
# pct_goal15%           -0.26      0.10    -0.46    -0.06 1.00     5136     2842

pred_summary_s2 <- ordinal_model_s2_probit %>%
  epred_draws(newdata = s2_agg, re_formula = NA) %>%
  group_by(refClass, rounded, pct_goal, .category) %>%
  summarise(
    mean_prob = mean(.epred),
    lower_ci = quantile(.epred, 0.025),
    upper_ci = quantile(.epred, 0.975),
    .groups = "drop"
  )

pred_summary_s2 |> pander::pandoc.table(caption="Study 1: Predicted probabilities of accuracy level by reference class")


# Extract posterior samples
posterior_samples_s2 <- as.data.frame(ordinal_model_s2_probit)


odds_ratios_s2 <- posterior_samples_s2 %>%
    transmute(
        refClass_Percentage_vs_kWh = exp(b_refClassPercentage),
        refClass_USD_vs_kWh = exp(b_refClassUSD),
        rounded_Yes_vs_No = exp(b_roundedRounded),
        pct_goal_15_vs_10 = exp(`b_pct_goal15%`)  # Note the backticks here
    )


# Calculate summary statistics
odds_ratio_summary_s2 <- data.frame(
    comparison = c("Percentage vs kWh", "USD vs kWh", "Rounded vs Not", "15% Goal vs 10% Goal"),
    odds_ratio = c(
        mean(odds_ratios_s2$refClass_Percentage_vs_kWh),
        mean(odds_ratios_s2$refClass_USD_vs_kWh),
        mean(odds_ratios_s2$rounded_Yes_vs_No),
        mean(odds_ratios_s2$pct_goal_15_vs_10)
    ),
    ci_lower = c(
        quantile(odds_ratios_s2$refClass_Percentage_vs_kWh, 0.025),
        quantile(odds_ratios_s2$refClass_USD_vs_kWh, 0.025),
        quantile(odds_ratios_s2$rounded_Yes_vs_No, 0.025),
        quantile(odds_ratios_s2$pct_goal_15_vs_10, 0.025)
    ),
    ci_upper = c(
        quantile(odds_ratios_s2$refClass_Percentage_vs_kWh, 0.975),
        quantile(odds_ratios_s2$refClass_USD_vs_kWh, 0.975),
        quantile(odds_ratios_s2$rounded_Yes_vs_No, 0.975),
        quantile(odds_ratios_s2$pct_goal_15_vs_10, 0.975)
    )
)

#             comparison odds_ratio ci_lower ci_upper
# 1    Percentage vs kWh       1.99     0.73     4.43
# 2           USD vs kWh       3.69     1.33     8.29
# 3       Rounded vs Not       0.70     0.57     0.84
# 4 15% Goal vs 10% Goal       0.78     0.63     0.94

odds_ratio_summary_s2 |> pander::pandoc.table(caption="Study 2: Odds ratios of accuracy")



ggplot(pred_summary, 
        aes(x = .category, y = mean_prob, fill = refClass )) +
    geom_col(position = position_dodge(width = 0.8)) +
    geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
                    position = position_dodge(width = 0.8)) +
    labs(x = "Reference Class", 
        y = "Predicted Probability",
        fill = "Accuracy Level",
        title = "Predicted Probabilities of Accuracy Levels by Reference Class") +
    scale_fill_brewer(palette = "RdYlBu") +
    theme_minimal() 




marginal_effects(ordinal_model_s2_probit)


```


## S2 logit version
```{r}



ordinal_model_s2_logit <- brm(
  accuracy_level ~ refClass +rounded+pct_goal + (1|id)+ (1|state),
  data = s2_agg,
  family = cumulative("logit"),
  cores = 4,
  iter = 2000,
  control = list(adapt_delta = 0.99), # Recommended for ordinal models
  prior = c(prior(normal(0, 2), class = "Intercept"),  # Priors for thresholds
            prior(normal(0, 2), class = "b")), # Priors for predictors
  file = paste0(here::here("data/model_cache",'s2_logit_add.rds')) # Cache for efficiency
)
summary(ordinal_model_s2_logit)
# Regression Coefficients:
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept[1]          -2.13      0.64    -3.39    -0.86 1.00      639     1328
# Intercept[2]          -0.62      0.63    -1.89     0.63 1.00      658     1366
# Intercept[3]           3.15      0.65     1.88     4.42 1.00      717     1638
# refClassPercentage     0.83      0.75    -0.64     2.33 1.00      452     1253
# refClassUSD            1.87      0.79     0.31     3.35 1.00      508     1260
# roundedRounded        -0.66      0.18    -1.01    -0.31 1.00     4276     3095
# pct_goal15%           -0.44      0.18    -0.79    -0.10 1.00     6263     3109


pred_summary_s2 <- ordinal_model_s2_logit %>%
  epred_draws(newdata = s2_agg, re_formula = NA) %>%
  group_by(refClass, rounded, pct_goal, .category) %>%
  summarise(
    mean_prob = mean(.epred),
    lower_ci = quantile(.epred, 0.025),
    upper_ci = quantile(.epred, 0.975),
    .groups = "drop"
  )

pred_summary_s2 |> pander::pandoc.table(caption="Study 1: Predicted probabilities of accuracy level by reference class")


```


### logit vs. probit 

```{r}

loo_logit <- loo(ordinal_model_s2_logit)
loo_probit <- loo(ordinal_model_s2_probit)
loo_compare(loo_logit, loo_probit)

waic(ordinal_model_s2_logit)
waic(ordinal_model_s2_probit)

# compare
rstanarm::loo_compare(loo_logit, loo_probit)

pp_check(ordinal_model_s2_logit, type = "bars_grouped", group="refClass", fatten = 2) +
  scale_x_continuous("Response Category", breaks = 1:4, 
            labels = c("Exact", "0.01-2%", "2.01-15%", ">15%")) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
  ggtitle("Posterior Predictive Check by Reference Class - logit") +
  theme_minimal() +
  theme(
    legend.background = element_blank(),
    legend.position = "bottom",
    panel.grid.minor = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1))
    
    
    
pp_check(ordinal_model_s2_probit, type = "bars_grouped", group="refClass", fatten = 2) +
  scale_x_continuous("Response Category", breaks = 1:4, 
            labels = c("Exact", "0.01-2%", "2.01-15%", ">15%")) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
  ggtitle("Posterior Predictive Check by Reference Class - probit") +
  theme_minimal() +
  theme(
    legend.background = element_blank(),
    legend.position = "bottom",
    panel.grid.minor = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1))
    

```



## Interaction model 

```{r}
#| eval: false

# Fit the full model with interactions
ordinal_model_s2 <- brm(
  accuracy_level ~ refClass * rounded * pct_goal + (1|id) + (1|state),
  data = s2_agg,
  family = cumulative("logit"),
  cores = 4,
  iter = 2000,
  control = list(adapt_delta = 0.99),
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "b")
  ),
  file = paste0(here::here("data/model_cache","s2_ordinal_full6.rds"))
)






pred_summary_s2 <- ordinal_model_s2 %>%
  epred_draws(newdata = s2_agg, re_formula = NA) %>%
  group_by(refClass, rounded, pct_goal, .category) %>%
  summarise(
    mean_prob = mean(.epred),
    lower_ci = quantile(.epred, 0.025),
    upper_ci = quantile(.epred, 0.975),
    .groups = "drop"
  )

# |refClass   |rounded     |pct_goal |.category      | mean_prob| lower_ci| upper_ci|
# |:----------|:-----------|:--------|:--------------|---------:|--------:|--------:|
# |kWh        |Not Rounded |10%      |Exact match    |      0.09|     0.02|     0.25|
# |kWh        |Not Rounded |10%      |0.01-2% error  |      0.20|     0.06|     0.36|
# |kWh        |Not Rounded |10%      |2.01-15% error |      0.64|     0.38|     0.77|
# |kWh        |Not Rounded |10%      |Over 15% error |      0.07|     0.01|     0.19|
# |kWh        |Not Rounded |15%      |Exact match    |      0.19|     0.05|     0.44|
# |kWh        |Not Rounded |15%      |0.01-2% error  |      0.29|     0.14|     0.41|
# |kWh        |Not Rounded |15%      |2.01-15% error |      0.49|     0.22|     0.73|
# |kWh        |Not Rounded |15%      |Over 15% error |      0.03|     0.01|     0.09|
# |kWh        |Rounded     |10%      |Exact match    |      0.22|     0.06|     0.49|
# |kWh        |Rounded     |10%      |0.01-2% error  |      0.31|     0.16|     0.41|
# |kWh        |Rounded     |10%      |2.01-15% error |      0.45|     0.18|     0.71|
# |kWh        |Rounded     |10%      |Over 15% error |      0.02|     0.00|     0.07|
# |kWh        |Rounded     |15%      |Exact match    |      0.28|     0.07|     0.61|
# |kWh        |Rounded     |15%      |0.01-2% error  |      0.32|     0.18|     0.42|
# |kWh        |Rounded     |15%      |2.01-15% error |      0.38|     0.11|     0.68|
# |kWh        |Rounded     |15%      |Over 15% error |      0.02|     0.00|     0.06|
# |Percentage |Not Rounded |10%      |Exact match    |      0.04|     0.01|     0.13|
# |Percentage |Not Rounded |10%      |0.01-2% error  |      0.12|     0.03|     0.28|
# |Percentage |Not Rounded |10%      |2.01-15% error |      0.70|     0.53|     0.78|
# |Percentage |Not Rounded |10%      |Over 15% error |      0.14|     0.03|     0.38|
# |Percentage |Not Rounded |15%      |Exact match    |      0.10|     0.02|     0.29|
# |Percentage |Not Rounded |15%      |0.01-2% error  |      0.21|     0.06|     0.37|
# |Percentage |Not Rounded |15%      |2.01-15% error |      0.63|     0.34|     0.77|
# |Percentage |Not Rounded |15%      |Over 15% error |      0.07|     0.01|     0.20|
# |Percentage |Rounded     |10%      |Exact match    |      0.15|     0.03|     0.40|
# |Percentage |Rounded     |10%      |0.01-2% error  |      0.26|     0.09|     0.39|
# |Percentage |Rounded     |10%      |2.01-15% error |      0.55|     0.24|     0.75|
# |Percentage |Rounded     |10%      |Over 15% error |      0.04|     0.01|     0.13|
# |Percentage |Rounded     |15%      |Exact match    |      0.13|     0.03|     0.35|
# |Percentage |Rounded     |15%      |0.01-2% error  |      0.25|     0.09|     0.39|
# |Percentage |Rounded     |15%      |2.01-15% error |      0.57|     0.28|     0.76|
# |Percentage |Rounded     |15%      |Over 15% error |      0.05|     0.01|     0.14|
# |USD        |Not Rounded |10%      |Exact match    |      0.02|     0.00|     0.07|
# |USD        |Not Rounded |10%      |0.01-2% error  |      0.07|     0.01|     0.19|
# |USD        |Not Rounded |10%      |2.01-15% error |      0.67|     0.42|     0.78|
# |USD        |Not Rounded |10%      |Over 15% error |      0.24|     0.06|     0.56|
# |USD        |Not Rounded |15%      |Exact match    |      0.06|     0.01|     0.18|
# |USD        |Not Rounded |15%      |0.01-2% error  |      0.14|     0.03|     0.32|
# |USD        |Not Rounded |15%      |2.01-15% error |      0.68|     0.47|     0.78|
# |USD        |Not Rounded |15%      |Over 15% error |      0.13|     0.02|     0.37|
# |USD        |Rounded     |10%      |Exact match    |      0.05|     0.01|     0.18|
# |USD        |Rounded     |10%      |0.01-2% error  |      0.13|     0.03|     0.32|
# |USD        |Rounded     |10%      |2.01-15% error |      0.68|     0.47|     0.78|
# |USD        |Rounded     |10%      |Over 15% error |      0.13|     0.02|     0.37|
# |USD        |Rounded     |15%      |Exact match    |      0.04|     0.01|     0.14|
# |USD        |Rounded     |15%      |0.01-2% error  |      0.11|     0.02|     0.28|
# |USD        |Rounded     |15%      |2.01-15% error |      0.69|     0.50|     0.78|
# |USD        |Rounded     |15%      |Over 15% error |      0.15|     0.03|     0.41|



# Extract posterior samples
posterior_samples_s2 <- as.data.frame(ordinal_model_s2)


odds_ratios_s2 <- posterior_samples_s2 %>%
    transmute(
        refClass_Percentage_vs_kWh = exp(b_refClassPercentage),
        refClass_USD_vs_kWh = exp(b_refClassUSD),
        rounded_Yes_vs_No = exp(b_roundedRounded),
        pct_goal_15_vs_10 = exp(`b_pct_goal15%`)  # Note the backticks here
    )
# Calculate summary statistics
odds_ratio_summary_s2 <- data.frame(
    comparison = c("Percentage vs kWh", "USD vs kWh", "Rounded vs Not", "15% Goal vs 10% Goal"),
    odds_ratio = c(
        mean(odds_ratios_s2$refClass_Percentage_vs_kWh),
        mean(odds_ratios_s2$refClass_USD_vs_kWh),
        mean(odds_ratios_s2$rounded_Yes_vs_No),
        mean(odds_ratios_s2$pct_goal_15_vs_10)
    ),
    ci_lower = c(
        quantile(odds_ratios_s2$refClass_Percentage_vs_kWh, 0.025),
        quantile(odds_ratios_s2$refClass_USD_vs_kWh, 0.025),
        quantile(odds_ratios_s2$rounded_Yes_vs_No, 0.025),
        quantile(odds_ratios_s2$pct_goal_15_vs_10, 0.025)
    ),
    ci_upper = c(
        quantile(odds_ratios_s2$refClass_Percentage_vs_kWh, 0.975),
        quantile(odds_ratios_s2$refClass_USD_vs_kWh, 0.975),
        quantile(odds_ratios_s2$rounded_Yes_vs_No, 0.975),
        quantile(odds_ratios_s2$pct_goal_15_vs_10, 0.975)
    )
)

#  odds_ratio_summary_s2
#             comparison odds_ratio ci_lower ci_upper
# 1    Percentage vs kWh       3.31     0.43     11.3
# 2           USD vs kWh       6.64     0.84     25.2
# 3       Rounded vs Not       0.41     0.09      1.1
# 4 15% Goal vs 10% Goal       0.51     0.12      1.5


odds_ratio_summary_s2 |> kable()


```


|comparison           | odds_ratio| ci_lower| ci_upper|
|:--------------------|----------:|--------:|--------:|
|Percentage vs kWh    |       3.31|     0.43|     11.2|
|USD vs kWh           |       6.64|     0.84|     25.2|
|Rounded vs Not       |       0.41|     0.09|      1.1|
|15% Goal vs 10% Goal |       0.51|     0.12|      1.5|



```{r}
#| eval: false



s2_agg <- s2_agg %>%
  mutate(
    refClass = factor(refClass, levels = c("kWh", "Percentage", "USD")),
    rounded = factor(rounded, levels = c("Not Rounded", "Rounded")),
    pct_goal = factor(pct_goal, levels = c("10%", "15%"))
  )

# Fit the full model with interactions
ordinal_model_s2 <- brm(
  accuracy_level ~ refClass * rounded * pct_goal + (1|id) + (1|state),
  data = s2_agg,
  family = cumulative("logit"),
  cores = 4,
  iter = 2000,
  control = list(adapt_delta = 0.99),
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "b")
  ),
  file = paste0(here::here("data/model_cache","s2_ordinal_full6.rds"))
)



pred_summary_s2 <- ordinal_model_s2 %>%
  epred_draws(newdata = s2_agg, re_formula = NA) %>%
  group_by(refClass, rounded, pct_goal, .category) %>%
  summarise(
    mean_prob = mean(.epred),
    lower_ci = quantile(.epred, 0.025),
    upper_ci = quantile(.epred, 0.975),
    .groups = "drop"
  )

# Extract posterior samples
posterior_samples_s2 <- as.data.frame(ordinal_model_s2)

# Compute odds ratios for the predictors
odds_ratios_s2 <- posterior_samples_s2 %>%
  transmute(
    refClass_Percentage_vs_kWh = exp(b_refClassPercentage),
    refClass_USD_vs_kWh = exp(b_refClassUSD),
    rounded_Yes_vs_No = exp(b_roundedRounded),
    pct_goal_15_vs_10 = exp(`b_pct_goal15%`)  # Note the backticks here
  )

# Summarize odds ratios
odds_ratio_summary_s2 <- odds_ratios_s2 %>%
  summarise(
    Percentage_vs_kWh = mean(refClass_Percentage_vs_kWh),
    USD_vs_kWh = mean(refClass_USD_vs_kWh),
    Rounded_vs_Not = mean(rounded_Yes_vs_No),
    Goal15_vs_Goal10 = mean(pct_goal_15_vs_10)
  )

odds_ratio_summary_s2
#   Percentage_vs_kWh USD_vs_kWh Rounded_vs_Not Goal15_vs_Goal10
# 1               3.3        6.6           0.41             0.51





```




# 3 level




```{r}
s1_aggb <- s1 |> 
    filter(appliance !="Total kWh") |> 
    group_by(id,refClass,state,block,plan,edu,pct_goal,calc) |> 
    summarise(total_kWh = sum(value),orig_kWh=sum(family), 
                pct_change = abs(round((orig_kWh-total_kWh)/orig_kWh,3)), 
                n_change = sum(value!=family),
                state_p_dif=mean(state_p_dif),
                state_f_dif=mean(state_f_dif),
                n_less_avg = sum(less_avg),
                duration=first(Duration__in_seconds_)) |> 
    mutate(matched_goal = (pct_change == pct_goal), 
                error = pct_change - pct_goal,
                abs_error = abs(error),
                log_abs_error=log(abs(error)+.007), 
                close_match = abs_error <= 0.02) |>
    ungroup() |> # Add ungroup here
        mutate(
            accuracy_level = factor(
                case_when(
                    abs_error == 0.00 ~ "Exact match",
                    abs_error <= 0.05 ~ "0.01-5% error",
                    TRUE ~ "Over 5% error"  # Capture all remaining cases
                ), 
                levels = c("Exact match", "0.01-5% error", "Over 5% error"),
                ordered = TRUE
            )
        ) |> relocate(accuracy_level, .after= "pct_change")



ggplot(data = s1_aggb, aes(x = refClass, fill = accuracy_level)) +
  geom_bar(position = "dodge", aes(y = (..count..)/sum(..count..))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Accuracy Levels by Reference Class",
       x = "Accuracy Level",
       y = "Percentage of Participants",
       fill = "Reference Class") +
  theme_minimal()






library(lmerTest)
mixed_model_abs_error <- lmer(log_abs_error ~ refClass+calc+ (1+plan|id) + (1|state), data = s1_aggb)
summary(mixed_model_abs_error)

logistic_model_clean_mixed <- glmer(matched_goal ~ refClass +calc+ (1|id) + (1|state), data = s1_aggb, family = binomial)
summary(logistic_model_clean_mixed)
emmeans::emmeans(logistic_model_clean_mixed, pairwise ~ refClass)


mixed_model_abs_error <- lmer(log_abs_error ~  refClass+calc +(1|state)+ (1|id), data = s1_aggb)
summary(mixed_model_abs_error)
emmeans::emmeans(mixed_model_abs_error, pairwise ~ refClass)


# categorial mixed effects regression on accuracy_level (ordered factor) with clean data (frequentist)
ordinal_model_clean_mixed <- clmm(accuracy_level ~ refClass +calc + (1|id) + (1|state), data = s1_aggb)
summary(ordinal_model_clean_mixed)
emmeans::emmeans(ordinal_model_clean_mixed, pairwise ~ refClass)



ordinal_model_s1 <- brm(
    accuracy_level ~ refClass +calc + (1|id) + (1|state),
    data = s1_aggb,
    family = cumulative("logit"),
    cores = 4,
    iter = 4000,
    control = list(adapt_delta = 0.98), 
    prior = c(prior(normal(0, 4), class = "Intercept"), 
                prior(normal(0, 4), class = "b")), 
    file = paste0(here::here("data/model_cache",'s1_acc3_add.rds')) 
)
# summary(ordinal_model_s1)
#  Family: cumulative 
#   Links: mu = logit; disc = identity 
# Formula: accuracy_level ~ refClass + calc + (1 | id) + (1 | state) 
#    Data: s1_aggb (Number of observations: 940) 
#   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
#          total post-warmup draws = 8000
# 
# Multilevel Hyperparameters:
# ~id (Number of levels: 235) 
#               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# sd(Intercept)     3.90      0.35     3.27     4.64 1.00     2072     4098
# 
# ~state (Number of levels: 4) 
#               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# sd(Intercept)     0.58      0.45     0.12     1.78 1.00     2961     2957
# 
# Regression Coefficients:
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept[1]          -4.21      0.85    -5.90    -2.58 1.00     1567     2898
# Intercept[2]          -0.89      0.82    -2.49     0.71 1.00     1528     2564
# refClassPercentage     1.44      0.71     0.07     2.88 1.00     1348     2624
# refClassUSD            3.13      0.69     1.81     4.50 1.00     1373     2564
# calcUsedCalculator    -3.30      0.73    -4.80    -1.92 1.00     1491     2765

pp_check(ordinal_model_s1, type = "bars_grouped", group="refClass", fatten = 2)
pp_check(ordinal_model_s1, type = "dens_overlay_grouped", group="refClass", fatten = 2,ndraws=100) 

ame1 <- avg_slopes(
  ordinal_model_s1, 
  variables = "refClass"
)
print(ame1)
 #         Group         Contrast Estimate   2.5 %   97.5 %
 # Exact match   Percentage - kWh  -0.1064 -0.2164 -0.00504
 # Exact match   USD - kWh         -0.2001 -0.2988 -0.10898
 # 0.01-5% error Percentage - kWh  -0.0211 -0.0577  0.00242
 # 0.01-5% error USD - kWh         -0.0811 -0.1143 -0.04856
 # Over 5% error Percentage - kWh   0.1314  0.0063  0.24907
 # Over 5% error USD - kWh          0.2842  0.1723  0.38086


as.data.frame(fixef(ordinal_model_s1)[,-2])|> as.data.frame() %>%
    rownames_to_column(var = "Parameter") %>%
    mutate(across(where(is.numeric), exp)) |>
    filter(!stringr::str_detect(Parameter, "Intercept")) |> 
    filter(!stringr::str_detect(Parameter, "calc")) |> 
    # rename columns to |comparison           | odds_ratio| ci_lower| ci_upper|
    rename(Comparison = Parameter, odds_ratio = Estimate, ci_lower = Q2.5, ci_upper = Q97.5) |>
    # rename levels to Percentage vs kWh; USD vs kWh; 
    mutate(Comparison = case_when(
        str_detect(Comparison, "refClassPercentage") ~ "Percentage vs kWh",
        str_detect(Comparison, "refClassUSD") ~ "USD vs kWh",
        TRUE ~ Comparison
    )) |> kable(escape=FALSE,booktabs=TRUE,align=c("l")) 

# |Comparison        |odds_ratio |ci_lower |ci_upper |
# |:-----------------|:----------|:--------|:--------|
# |Percentage vs kWh |4.2        |1.1      |18       |
# |USD vs kWh        |22.9       |6.1      |90       |
```


```{r}

condEffects <- function(m,xvar){
  m |> ggplot(aes(x = {{xvar}}, y = .value, color = refClass, fill = refClass)) + 
  stat_dist_pointinterval() + 
  stat_halfeye(alpha=.1, height=.5) +
  theme(legend.title=element_blank(),axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5)) 
  
}
```



```{r}


s2_agg <- s2_long |> 
  filter(appliance != "TOTAL") |> 
  group_by(id,refClass,calc, state,pct,pct_goal,plan,rounded) |> 
  summarise(
    total_kWh = sum(value),
    orig_kWh = sum(family),
    pct_change = round((orig_kWh - total_kWh) / orig_kWh, 3),
    state_dif = mean(state_dif),
    .groups = "drop"
  ) |>
  mutate(
    matched_goal = (pct_change == pct),
    close_match = abs(pct_change - pct) <= 0.02,
                error = pct_change - pct,
                abs_error = abs(error),
                log_abs_error=log(abs(error)+.007)) |> 
      ungroup() |> 
        mutate(
            accuracy_level = factor(
                case_when(
                    abs_error == 0.00 ~ "Exact match",
                    abs_error <= 0.05 ~ "0.01-5% error",
                    TRUE ~ "Over 5% error"  # Capture all remaining cases
                ), 
                levels = c("Exact match","0.01-5% error", "Over 5% error"),
                ordered = TRUE
            )
        )

ggplot(data = s2_agg, aes(x = refClass, fill = accuracy_level)) +
  geom_bar(position = "dodge", aes(y = (..count..)/sum(..count..))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Accuracy Levels by Reference Class",
       x = "Accuracy Level",
       y = "Percentage of Participants",
       fill = "Reference Class") +
  theme_minimal()





library(lmerTest)
mixed_model_abs_error <- lmer(log_abs_error ~ refClass + calc+ (1|id) + (1|state), data = s2_agg)
summary(mixed_model_abs_error)




logistic_model_clean_mixed <- glmer(matched_goal ~ refClass+calc+pct_goal+rounded +(1|state)+ (1|id) , data = s2_agg, family = binomial)
summary(logistic_model_clean_mixed)
emmeans::emmeans(logistic_model_clean_mixed, pairwise ~ refClass)



mixed_model_abs_error <- lmer(log_abs_error ~  refClass+calc+pct_goal+rounded +(1|state)+ (1|id), data = s2_agg)
summary(mixed_model_abs_error)
emmeans::emmeans(mixed_model_abs_error, pairwise ~ refClass)


library(ordinal)    
library(parameters) 

# categorial mixed effects regression on accuracy_level (ordered factor) with clean data (frequentist)
ordinal_model_clean_mixed <- clmm(accuracy_level ~ refClass + calc+pct_goal+rounded + (1|id) + (1|state), data = s2_agg)
summary(ordinal_model_clean_mixed)
emmeans::emmeans(ordinal_model_clean_mixed, pairwise ~ refClass)


ordinal_model_clean_mixed <- clmm(accuracy_level ~ (refClass*pct_goal*rounded)+ calc + (1|id) + (1|state), data = s2_agg)
summary(ordinal_model_clean_mixed)
emmeans::emmeans(ordinal_model_clean_mixed, pairwise ~ refClass)
pairs(emmeans(ordinal_model_clean_mixed, ~ refClass | rounded +pct_goal+calc))




ordinal_model_clean_mixed <- clmm(accuracy_level ~ refClass + rounded + pct_goal + calc + refClass:calc+refClass:rounded + refClass:pct_goal + rounded:pct_goal + (1|id) + (1|state), data = s2_agg)
summary(ordinal_model_clean_mixed)
emmeans::emmeans(ordinal_model_clean_mixed, pairwise ~ refClass+calc)

emms_ref <- emmeans(ordinal_model_clean_mixed, ~ refClass, type = "link")
contrast_ref <- contrast(emms_ref, "trt.vs.ctrl", ref = "kWh") 
odds_ratios <- summary(contrast_ref, type = "response") # back-transform to odds
odds_ratios


pairs(emmeans(ordinal_model_clean_mixed, ~ refClass | rounded +pct_goal+calc))
pairs(emmeans(ordinal_model_clean_mixed, ~ refClass+calc))








# ordinal regression
polr_model <- MASS::polr(accuracy_level ~ refClass + calc, data = s2_agg)
summary(polr_model)
emmeans::emmeans(polr_model, pairwise ~ refClass+calc)






m_equal <- clm(accuracy_level ~ refClass+calc+pct_goal+rounded, 
    data = s2_agg, 
    link="probit")


parameters::model_parameters(m_equal) |> 
  insight::print_html()
summary(m_equal)


ame_by_rounded_pct_goal <- avg_slopes(
  m_equal,
  variables = "refClass",
  by = c("rounded", "pct_goal", "accuracy_level")
)



ordinal_model_s2_logit <- brm(
  accuracy_level ~ refClass + calc+pct_goal+rounded + (1|id)+ (1|state),
  data = s2_agg,
  family = cumulative("logit"),
  cores = 4,
  iter = 3000,
  control = list(adapt_delta = 0.99), # Recommended for ordinal models
  prior = c(prior(normal(0, 2), class = "Intercept"),  # Priors for thresholds
            prior(normal(0, 2), class = "b")), # Priors for predictors
  file = paste0(here::here("data/model_cache",'s2_acc3_add.rds')) # Cache for efficiency
)
# summary(ordinal_model_s2_logit)
#  Family: cumulative 
#   Links: mu = logit; disc = identity 
# Formula: accuracy_level ~ refClass + calc + pct_goal + rounded + (1 | id) + (1 | state) 
#    Data: s2_agg1b (Number of observations: 784) 
#   Draws: 4 chains, each with iter = 3000; warmup = 1500; thin = 1;
#          total post-warmup draws = 6000
# 
# Multilevel Hyperparameters:
# ~id (Number of levels: 196) 
#               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# sd(Intercept)     4.88      0.51     3.98     5.99 1.00     1473     2687
# 
# ~state (Number of levels: 4) 
#               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# sd(Intercept)     0.38      0.39     0.01     1.42 1.00     1834     2700
# 
# Regression Coefficients:
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept[1]          -1.45      0.70    -2.85    -0.07 1.00     1200     1896
# Intercept[2]           1.26      0.68    -0.09     2.65 1.00     1171     2064
# refClassPercentage     1.02      0.84    -0.63     2.71 1.01      807     1901
# refClassUSD            2.27      0.89     0.53     3.98 1.00      995     1835
# calcNoCalculator       4.10      0.98     2.20     6.06 1.00     1876     3213
# pct_goal15%           -0.39      0.22    -0.81     0.04 1.00     7847     4569
# roundedRounded        -0.53      0.22    -0.96    -0.11 1.00     8353     4931





conditional_effects(ordinal_model_s2_logit)

pp_check(ordinal_model_s2_logit, type = "bars_grouped", group="refClass", fatten = 2) +
  scale_x_continuous("Response Category", breaks = 1:3, 
            labels = c("Exact", "0.01-5%", ">5%")) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
  ggtitle("Posterior Predictive Check by Reference Class") +
  theme_minimal() +
  theme(
    legend.background = element_blank(),
    legend.position = "bottom",
    panel.grid.minor = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1))

ame2 <- avg_slopes(
  ordinal_model_s2_logit, 
  variables = "refClass",
  ndraws=200
)
print(ame2)

avg_slopes(
  ordinal_model_s2_logit, 
  variables = "refClass", type="response"
)

ame_by_rounded <- avg_slopes(
  ordinal_model_s2_logit,
  variables = "refClass",
  by = c("rounded", "accuracy_level")
)
print(ame_by_rounded)


ame_by_rounded_pct_goal <- avg_slopes(
  ordinal_model_s2_logit,
  variables = "refClass",
  by = c("rounded", "pct_goal", "accuracy_level")
)
print(ame_by_rounded_pct_goal)


ordinal_model_s2_logit |> emmeans(~refClass+pct_goal, at=list(pct_goal=c("10%","15%"),  re_formula=NA)) |> 
  gather_emmeans_draws() |> 
  condEffects(pct_goal)

ordinal_model_s2_logit |> emmeans(~refClass+calc, at=list(calc=c('Calculator', 'No Calculator'),  re_formula=NA)) |> 
  gather_emmeans_draws() |> 
  condEffects(calc)





emmeans::emmeans(ordinal_model_s2_logit, pairwise ~ refClass)
# $contrasts
#  contrast         estimate lower.HPD upper.HPD
#  kWh - Percentage    -1.01      -2.6      0.68
#  kWh - USD           -2.29      -4.0     -0.52
#  Percentage - USD    -1.23      -3.1      0.60
# 
# Results are averaged over the levels of: calc, pct_goal, rounded 
# Point estimate displayed: median 
# Results are given on the log odds ratio (not the response) scale. 
# HPD interval probability: 0.95 

emmeans::emmeans(ordinal_model_s2_logit, pairwise ~ refClass,type="response")

emmeans::emmeans(ordinal_model_s2_logit,~ refClass,type="response") |> contrast(method="revpairwise") 

emmeans::emmeans(ordinal_model_s2_logit,~ refClass+calc+pct_goal+rounded) |> contrast(method="revpairwise") 


avg_predictions(ordinal_model_s2_logit, newdata = datagrid(refClass=unique),by="refClass")
avg_predictions(ordinal_model_s2_logit, newdata = datagrid(id=unique,refClass=unique),by="refClass")
avg_slopes(ordinal_model_s2_logit, variables="refClass",type="response",by="refClass")


 ordinal_model_s2_logit |> emmeans(pairwise~ refClass, re_formula=NA)  |> 
  pluck("contrasts") |>
  gather_emmeans_draws() |> 
  group_by(contrast,.draw) |> summarise(value=mean(.value), n=n()) |> 
  # filter(!(contrast %in% c("ALM Constant - EXAM Constant","ALM Constant - EXAM Varied","ALM Varied - EXAM Varied ", "EXAM Constant - ALM Varied" ))) |> 
  ggplot(aes(x=value,y=contrast,fill=contrast)) +stat_halfeye() + labs(x="Model Error Difference",y="Contrast") + theme(legend.position="none") 




emm_ref_all <- emmeans(ordinal_model_s2_logit, ~ refClass, type="prob", levels=levels(s2_agg1b$accuracy_level))
emm_pairs <- pairs(emm_ref_all)
emm_pairs


avg_preds <- predictions(ordinal_model_s2_logit, 
                                 newdata = datagrid(id=unique,refClass = unique),
                                 by="refClass") |> as.data.frame() |> 
  mutate(refClass = factor(refClass, levels = c("kWh", "Percentage", "USD"))) 


predictions(ordinal_model_s2_logit, 
                                 newdata = datagrid(id=unique,refClass = unique(s2_agg1b$refClass)),
                                 by="refClass") 


predictions(ordinal_model_s2_logit, newdata = datagrid(id=unique,refClass=unique,calc=unique)) |> 
  mutate(.value=estimate) |>
  condEffects(refClass) + facet_wrap(~group, scales = "free")


```

